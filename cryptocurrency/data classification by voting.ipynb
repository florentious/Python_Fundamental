{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "# 시간계산을 위함\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pymysql\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectDJ() : \n",
    "    tmp_df = pd.DataFrame([])\n",
    "    \n",
    "    tmp_date = np.array([])\n",
    "    tmp_close = np.array([])\n",
    "    tmp_open = np.array([])\n",
    "    tmp_high = np.array([])\n",
    "    tmp_low = np.array([])\n",
    "    tmp_volume = np.array([])\n",
    "\n",
    "    # db 커넥션 연결\n",
    "    conn = pymysql.connect(host='localhost', port=3306,\n",
    "                           user='acorn12', passwd='acorn12', db='acorn', charset='utf8')\n",
    "\n",
    "#     conn = pymysql.connect(host='localhost', port=3306,\n",
    "#                            user='flo', passwd='flo', db='db', charset='utf8')\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = 'SELECT dj_date, dj_close, dj_open, dj_high, dj_low, dj_volume FROM dowjones '\n",
    "\n",
    "            cursor.execute(sql)\n",
    "            conn.commit()\n",
    "\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            for i in range(len(rows)) :\n",
    "                tmp_date = np.append(tmp_date, rows[i][0])\n",
    "                tmp_close = np.append(tmp_close, rows[i][1])\n",
    "                tmp_open = np.append(tmp_open, rows[i][2])\n",
    "                tmp_high = np.append(tmp_high, rows[i][3])\n",
    "                tmp_low = np.append(tmp_low, rows[i][4])\n",
    "                tmp_volume = np.append(tmp_volume, rows[i][5])\n",
    "                \n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    tmp_df['date'] = tmp_date.astype('datetime64[ns]')\n",
    "    tmp_df['close'] = tmp_close\n",
    "    tmp_df['open'] = tmp_open\n",
    "    tmp_df['high'] = tmp_high\n",
    "    tmp_df['low'] = tmp_low\n",
    "    tmp_df['volume'] = tmp_volume\n",
    "    \n",
    "    tmp_df = tmp_df.set_index('date')\n",
    "    \n",
    "    return(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectGold() : \n",
    "    tmp_df = pd.DataFrame([])\n",
    "    \n",
    "    tmp_date = np.array([])\n",
    "    tmp_close = np.array([])\n",
    "    tmp_open = np.array([])\n",
    "    tmp_high = np.array([])\n",
    "    tmp_low = np.array([])\n",
    "    tmp_volume = np.array([])\n",
    "    # db 커넥션 연결\n",
    "    conn = pymysql.connect(host='localhost', port=3306,\n",
    "                           user='acorn12', passwd='acorn12', db='acorn', charset='utf8')\n",
    "\n",
    "#     conn = pymysql.connect(host='localhost', port=3306,\n",
    "#                            user='flo', passwd='flo', db='db', charset='utf8')\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = 'SELECT gold_date, gold_close, gold_open, gold_high, gold_low, gold_volume '\n",
    "            sql += 'FROM gold '\n",
    "\n",
    "            cursor.execute(sql)\n",
    "            conn.commit()\n",
    "\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            for i in range(len(rows)) :\n",
    "                tmp_date = np.append(tmp_date, rows[i][0])\n",
    "                tmp_close = np.append(tmp_close, rows[i][1])\n",
    "                tmp_open = np.append(tmp_open, rows[i][2])\n",
    "                tmp_high = np.append(tmp_high, rows[i][3])\n",
    "                tmp_low = np.append(tmp_low, rows[i][4])\n",
    "                tmp_volume = np.append(tmp_volume, rows[i][5])\n",
    "                \n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    tmp_df['date'] = tmp_date.astype('datetime64[ns]')\n",
    "    tmp_df['close'] = tmp_close\n",
    "    tmp_df['open'] = tmp_open\n",
    "    tmp_df['high'] = tmp_high\n",
    "    tmp_df['low'] = tmp_low\n",
    "    tmp_df['volume'] = tmp_volume\n",
    "    \n",
    "    tmp_df = tmp_df.set_index('date')\n",
    "    \n",
    "    return(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBitcoin() : \n",
    "    tmp_df = pd.DataFrame([])\n",
    "    \n",
    "    tmp_date = np.array([])\n",
    "    tmp_close = np.array([])\n",
    "    tmp_open = np.array([])\n",
    "    tmp_high = np.array([])\n",
    "    tmp_low = np.array([])\n",
    "    tmp_volume = np.array([])\n",
    "    # db 커넥션 연결\n",
    "    conn = pymysql.connect(host='localhost', port=3306,\n",
    "                           user='acorn12', passwd='acorn12', db='acorn', charset='utf8')\n",
    "\n",
    "#     conn = pymysql.connect(host='localhost', port=3306,\n",
    "#                            user='flo', passwd='flo', db='db', charset='utf8')\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            sql = 'SELECT bit_date, bit_close, bit_open, bit_high, bit_low, bit_volume '\n",
    "            sql += 'FROM bitcoin '\n",
    "\n",
    "            cursor.execute(sql)\n",
    "            conn.commit()\n",
    "\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            for i in range(len(rows)) :\n",
    "                tmp_date = np.append(tmp_date, rows[i][0])\n",
    "                tmp_close = np.append(tmp_close, rows[i][1])\n",
    "                tmp_open = np.append(tmp_open, rows[i][2])\n",
    "                tmp_high = np.append(tmp_high, rows[i][3])\n",
    "                tmp_low = np.append(tmp_low, rows[i][4])\n",
    "                tmp_volume = np.append(tmp_volume, rows[i][5])\n",
    "                \n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    tmp_df['date'] = tmp_date.astype('datetime64[ns]')\n",
    "    tmp_df['close'] = tmp_close\n",
    "    tmp_df['open'] = tmp_open\n",
    "    tmp_df['high'] = tmp_high\n",
    "    tmp_df['low'] = tmp_low\n",
    "    tmp_df['volume'] = tmp_volume\n",
    "    \n",
    "    tmp_df = tmp_df.set_index('date')\n",
    "    \n",
    "    return(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dowjones_DF = selectDJ()\n",
    "gold_DF = selectGold()\n",
    "bitcoin_DF = selectBitcoin()\n",
    "\n",
    "dowjones_subDF = dowjones_DF.loc[:,['close','open']]\n",
    "gold_subDF = gold_DF.loc[:,['close','open']]\n",
    "bitcoin_subDF = bitcoin_DF.loc[:,['close','open']]\n",
    "\n",
    "dowjones_subDF = dowjones_subDF.add_prefix('dj_')\n",
    "gold_subDF = gold_subDF.add_prefix('gol_')\n",
    "bitcoin_subDF = bitcoin_subDF.add_prefix('bit_')\n",
    "\n",
    "result_sub = pd.concat([bitcoin_subDF, gold_subDF, dowjones_subDF], axis = 1, sort=False)\n",
    "\n",
    "# na 값에 대해서 padding 처리한 과정 : 값이 없으면 전날 데이터 기준으로 들어간다\n",
    "\n",
    "beforeDate = result_sub.index[0]\n",
    "\n",
    "for date in result_sub.index :\n",
    "    for cols in result_sub.columns :\n",
    "        if pd.isnull(result_sub.at[date,cols]) == True :\n",
    "            result_sub.at[date,cols] = result_sub.at[beforeDate,cols]\n",
    "    beforeDate = date\n",
    "\n",
    "\n",
    "# db 커넥션 연결\n",
    "conn = pymysql.connect(host='localhost', port=3306,\n",
    "                       user='acorn12', passwd='acorn12', db='acorn', charset='utf8')\n",
    "\n",
    "# conn = pymysql.connect(host='localhost', port=3306,\n",
    "#                        user='flo', passwd='flo', db='db', charset='utf8')\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = 'SELECT IFNULL(MAX(cl_date),\"2013-01-01\") FROM al_close '\n",
    "        \n",
    "        cursor.execute(sql)\n",
    "        \n",
    "        rows = cursor.fetchone()\n",
    "        lastDate = rows[0]\n",
    "        \n",
    "        # db에 기록된 가장 최근값과 오늘의 날짜 반납( 이 기준으로 db에서 가져옴)\n",
    "        \n",
    "        recentlyDate = pd.to_datetime(lastDate).date()\n",
    "        recentlyDate += dt.timedelta(days=1) # 하루 추가하기(다음날로 확인하는 거)\n",
    "        today = dt.datetime.now().date()\n",
    "        \n",
    "        result_sub_update = result_sub.loc[recentlyDate:,:]\n",
    "        \n",
    "        if recentlyDate < today :\n",
    "            for date in result_sub_update.index :\n",
    "\n",
    "                sql = 'INSERT INTO al_close(cl_date, cl_bitcoin, cl_gold, cl_dowjones) '\n",
    "                sql += 'VALUES(%s,%s,%s,%s) '\n",
    "\n",
    "                cursor.execute(sql,(date.date(),float(result_sub_update.at[date,'bit_close']),float(result_sub_update.at[date,'gol_close']),float(result_sub_update.at[date,'dj_close'])) )\n",
    "\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균선 feature 만들기\n",
    "def mkFeat(df,typeName) :\n",
    "    df[typeName+'_MA_5'] = df[typeName+'_close'].rolling(window=5).mean()\n",
    "    df[typeName+'_MA_60'] = df[typeName+'_close'].rolling(window=60).mean()\n",
    "\n",
    "\n",
    "# 차이 만들기\n",
    "def mkDif(df, typeName) :\n",
    "    df[typeName+'_dif'] = df[typeName+'_MA_5'] - df[typeName+'_MA_60']\n",
    "    df[typeName+'_dif_before_1d'] = df[typeName+'_dif'].shift(1)\n",
    "    \n",
    "# target 만들기\n",
    "\n",
    "def mkTarget(df, typeName) :\n",
    "    tmp_change = np.array([])\n",
    "    \n",
    "    df[typeName+'_close_after_1d'] = df[typeName+'_close'].shift(-1)\n",
    "    df.at[df.index[-1], typeName+'_close_after_1d'] = 0\n",
    "    for date in df.index :\n",
    "        tmp_change = np.append(tmp_change, (lambda x : 1 if x>0 else (-1 if x<0 else 0))(df.at[date,typeName+'_close_after_1d']-df.at[date,typeName+'_close']))\n",
    "    \n",
    "    df[typeName+'_change'] = tmp_change.astype('int64')\n",
    "    df.at[df.index[-1],typeName+'_change'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로 컨트롤할 데이터 출력\n",
    "upData = result_sub.loc[:,['bit_close','gol_close','dj_close']]\n",
    "\n",
    "# 실제 연산하는 자리\n",
    "dataList = ['bit','gol','dj']\n",
    "\n",
    "for cols in dataList :\n",
    "    mkFeat(upData,cols)\n",
    "    mkDif(upData,cols)\n",
    "    mkTarget(upData,cols)\n",
    "\n",
    "\n",
    "# 컬럼 순서 엉킨거 조정 및 필요없는거 제거\n",
    "upData = upData[['bit_close','bit_MA_5','bit_MA_60','bit_dif','bit_dif_before_1d',\n",
    "                 'gol_close','gol_MA_5','gol_MA_60','gol_dif','gol_dif_before_1d',\n",
    "                 'dj_close','dj_MA_5','dj_MA_60','dj_dif','dj_dif_before_1d',\n",
    "                 'bit_change','gol_change','dj_change'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2013-01-02      13.40\n",
       "2013-01-03      13.50\n",
       "2013-01-04      13.44\n",
       "2013-01-05      13.45\n",
       "2013-01-06      13.59\n",
       "               ...   \n",
       "2020-01-26    8912.00\n",
       "2020-01-27    9393.70\n",
       "2020-01-28    9304.20\n",
       "2020-01-29    9322.50\n",
       "2020-01-30        NaN\n",
       "Name: bit_close, Length: 2578, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = upData['bit_close'].shift(-1)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bit_close</th>\n",
       "      <th>bit_MA_5</th>\n",
       "      <th>bit_MA_60</th>\n",
       "      <th>bit_dif</th>\n",
       "      <th>bit_dif_before_1d</th>\n",
       "      <th>gol_close</th>\n",
       "      <th>gol_MA_5</th>\n",
       "      <th>gol_MA_60</th>\n",
       "      <th>gol_dif</th>\n",
       "      <th>gol_dif_before_1d</th>\n",
       "      <th>dj_close</th>\n",
       "      <th>dj_MA_5</th>\n",
       "      <th>dj_MA_60</th>\n",
       "      <th>dj_dif</th>\n",
       "      <th>dj_dif_before_1d</th>\n",
       "      <th>bit_change</th>\n",
       "      <th>gol_change</th>\n",
       "      <th>dj_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>13.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1687.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13412.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>13.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1673.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13391.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>13.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1648.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13435.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>13.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1648.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13435.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>13.45</td>\n",
       "      <td>13.414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1648.10</td>\n",
       "      <td>1661.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13435.21</td>\n",
       "      <td>13421.908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>9410.60</td>\n",
       "      <td>9359.680</td>\n",
       "      <td>7875.807000</td>\n",
       "      <td>1483.873000</td>\n",
       "      <td>1418.729333</td>\n",
       "      <td>1582.90</td>\n",
       "      <td>1579.72</td>\n",
       "      <td>1527.051667</td>\n",
       "      <td>52.668333</td>\n",
       "      <td>53.780000</td>\n",
       "      <td>28251.47</td>\n",
       "      <td>28563.866</td>\n",
       "      <td>28590.693167</td>\n",
       "      <td>-26.827167</td>\n",
       "      <td>41.986500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>9353.10</td>\n",
       "      <td>9351.560</td>\n",
       "      <td>7911.055167</td>\n",
       "      <td>1440.504833</td>\n",
       "      <td>1483.873000</td>\n",
       "      <td>1593.85</td>\n",
       "      <td>1582.46</td>\n",
       "      <td>1528.945833</td>\n",
       "      <td>53.514167</td>\n",
       "      <td>52.668333</td>\n",
       "      <td>28251.47</td>\n",
       "      <td>28469.754</td>\n",
       "      <td>28600.721333</td>\n",
       "      <td>-130.967333</td>\n",
       "      <td>-26.827167</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>9327.60</td>\n",
       "      <td>9356.240</td>\n",
       "      <td>7942.515167</td>\n",
       "      <td>1413.724833</td>\n",
       "      <td>1440.504833</td>\n",
       "      <td>1593.55</td>\n",
       "      <td>1585.83</td>\n",
       "      <td>1530.786667</td>\n",
       "      <td>55.043333</td>\n",
       "      <td>53.514167</td>\n",
       "      <td>28398.39</td>\n",
       "      <td>28402.292</td>\n",
       "      <td>28612.731333</td>\n",
       "      <td>-210.439333</td>\n",
       "      <td>-130.967333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>9197.40</td>\n",
       "      <td>9331.220</td>\n",
       "      <td>7969.333500</td>\n",
       "      <td>1361.886500</td>\n",
       "      <td>1413.724833</td>\n",
       "      <td>1557.85</td>\n",
       "      <td>1582.21</td>\n",
       "      <td>1532.332500</td>\n",
       "      <td>49.877500</td>\n",
       "      <td>55.043333</td>\n",
       "      <td>28808.64</td>\n",
       "      <td>28392.288</td>\n",
       "      <td>28625.957667</td>\n",
       "      <td>-233.669667</td>\n",
       "      <td>-210.439333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>9209.20</td>\n",
       "      <td>9299.580</td>\n",
       "      <td>7997.100167</td>\n",
       "      <td>1302.479833</td>\n",
       "      <td>1361.886500</td>\n",
       "      <td>1558.35</td>\n",
       "      <td>1577.30</td>\n",
       "      <td>1533.886667</td>\n",
       "      <td>43.413333</td>\n",
       "      <td>49.877500</td>\n",
       "      <td>29290.85</td>\n",
       "      <td>28600.164</td>\n",
       "      <td>28647.220833</td>\n",
       "      <td>-47.056833</td>\n",
       "      <td>-233.669667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bit_close  bit_MA_5    bit_MA_60      bit_dif  bit_dif_before_1d  \\\n",
       "date                                                                           \n",
       "2013-01-02      13.28       NaN          NaN          NaN                NaN   \n",
       "2013-01-03      13.40       NaN          NaN          NaN                NaN   \n",
       "2013-01-04      13.50       NaN          NaN          NaN                NaN   \n",
       "2013-01-05      13.44       NaN          NaN          NaN                NaN   \n",
       "2013-01-06      13.45    13.414          NaN          NaN                NaN   \n",
       "...               ...       ...          ...          ...                ...   \n",
       "2020-02-01    9410.60  9359.680  7875.807000  1483.873000        1418.729333   \n",
       "2020-02-02    9353.10  9351.560  7911.055167  1440.504833        1483.873000   \n",
       "2020-02-03    9327.60  9356.240  7942.515167  1413.724833        1440.504833   \n",
       "2020-02-04    9197.40  9331.220  7969.333500  1361.886500        1413.724833   \n",
       "2020-02-05    9209.20  9299.580  7997.100167  1302.479833        1361.886500   \n",
       "\n",
       "            gol_close  gol_MA_5    gol_MA_60    gol_dif  gol_dif_before_1d  \\\n",
       "date                                                                         \n",
       "2013-01-02    1687.90       NaN          NaN        NaN                NaN   \n",
       "2013-01-03    1673.70       NaN          NaN        NaN                NaN   \n",
       "2013-01-04    1648.10       NaN          NaN        NaN                NaN   \n",
       "2013-01-05    1648.10       NaN          NaN        NaN                NaN   \n",
       "2013-01-06    1648.10   1661.18          NaN        NaN                NaN   \n",
       "...               ...       ...          ...        ...                ...   \n",
       "2020-02-01    1582.90   1579.72  1527.051667  52.668333          53.780000   \n",
       "2020-02-02    1593.85   1582.46  1528.945833  53.514167          52.668333   \n",
       "2020-02-03    1593.55   1585.83  1530.786667  55.043333          53.514167   \n",
       "2020-02-04    1557.85   1582.21  1532.332500  49.877500          55.043333   \n",
       "2020-02-05    1558.35   1577.30  1533.886667  43.413333          49.877500   \n",
       "\n",
       "            dj_close    dj_MA_5      dj_MA_60      dj_dif  dj_dif_before_1d  \\\n",
       "date                                                                          \n",
       "2013-01-02  13412.55        NaN           NaN         NaN               NaN   \n",
       "2013-01-03  13391.36        NaN           NaN         NaN               NaN   \n",
       "2013-01-04  13435.21        NaN           NaN         NaN               NaN   \n",
       "2013-01-05  13435.21        NaN           NaN         NaN               NaN   \n",
       "2013-01-06  13435.21  13421.908           NaN         NaN               NaN   \n",
       "...              ...        ...           ...         ...               ...   \n",
       "2020-02-01  28251.47  28563.866  28590.693167  -26.827167         41.986500   \n",
       "2020-02-02  28251.47  28469.754  28600.721333 -130.967333        -26.827167   \n",
       "2020-02-03  28398.39  28402.292  28612.731333 -210.439333       -130.967333   \n",
       "2020-02-04  28808.64  28392.288  28625.957667 -233.669667       -210.439333   \n",
       "2020-02-05  29290.85  28600.164  28647.220833  -47.056833       -233.669667   \n",
       "\n",
       "            bit_change  gol_change  dj_change  \n",
       "date                                           \n",
       "2013-01-02         1.0        -1.0       -1.0  \n",
       "2013-01-03         1.0        -1.0        1.0  \n",
       "2013-01-04        -1.0         0.0        0.0  \n",
       "2013-01-05         1.0         0.0        0.0  \n",
       "2013-01-06         1.0        -1.0       -1.0  \n",
       "...                ...         ...        ...  \n",
       "2020-02-01        -1.0         1.0        0.0  \n",
       "2020-02-02        -1.0        -1.0        1.0  \n",
       "2020-02-03        -1.0        -1.0        1.0  \n",
       "2020-02-04         1.0         1.0        1.0  \n",
       "2020-02-05         NaN         NaN        NaN  \n",
       "\n",
       "[2584 rows x 18 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makedData 쪽 db 연결 및 데이터 채우기\n",
    "# 빈데이터에는 빈값을 넣기 위해서 각각의 자리에 라인 if/else 함수로 넣었음\n",
    "\n",
    "# db 커넥션 연결\n",
    "conn = pymysql.connect(host='localhost', port=3306,\n",
    "                       user='acorn12', passwd='acorn12', db='acorn', charset='utf8')\n",
    "\n",
    "# conn = pymysql.connect(host='localhost', port=3306,\n",
    "#                        user='flo', passwd='flo', db='db', charset='utf8')\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = 'SELECT IFNULL(MAX(md_date),\"2013-01-01\") FROM makedData '\n",
    "        \n",
    "        cursor.execute(sql)\n",
    "        \n",
    "        rows = cursor.fetchone()\n",
    "        lastDate = rows[0]\n",
    "        \n",
    "        # db에 기록된 가장 최근값과 오늘의 날짜 반납( 이 기준으로 db에서 가져옴)\n",
    "        \n",
    "        recentlyDate = pd.to_datetime(lastDate).date()\n",
    "        recentlyDate += dt.timedelta(days=1) # 하루 추가하기(다음날로 확인하는 거)\n",
    "        today = dt.datetime.now().date()\n",
    "        \n",
    "        result_sub_update = result_sub.loc[recentlyDate:,:]\n",
    "        \n",
    "        if recentlyDate < today :\n",
    "            for date in upData.index :\n",
    "\n",
    "                sql = 'INSERT INTO makedData(md_date, md_bit_close, md_bit_ma5, md_bit_ma60, md_bit_dif, md_bit_dif_b1, '\n",
    "                sql += 'md_gol_close, md_gol_ma5, md_gol_ma60, md_gol_dif, md_gol_dif_b1, '\n",
    "                sql += 'md_dj_close, md_dj_ma5, md_dj_ma60, md_dj_dif, md_dj_dif_b1, '\n",
    "                sql += 'md_bit_change, md_gol_change, md_dj_change) '\n",
    "                sql += 'VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) '\n",
    "\n",
    "                cursor.execute(sql,(date.date(),float(upData.at[date,'bit_close']),float(upData.at[date,'bit_MA_5']) if pd.notnull(upData.at[date,'bit_MA_5']) else None, float(upData.at[date,'bit_MA_60']) if pd.notnull(upData.at[date,'bit_MA_60']) else None, float(upData.at[date,'bit_dif']) if pd.notnull(upData.at[date,'bit_dif']) else None,float(upData.at[date,'bit_dif_before_1d']) if pd.notnull(upData.at[date,'bit_dif_before_1d']) else None,\n",
    "                                   float(upData.at[date,'gol_close']),float(upData.at[date,'gol_MA_5']) if pd.notnull(upData.at[date,'gol_MA_5']) else None,float(upData.at[date,'gol_MA_60']) if pd.notnull(upData.at[date,'gol_MA_60']) else None,float(upData.at[date,'gol_dif']) if pd.notnull(upData.at[date,'gol_dif']) else None,float(upData.at[date,'gol_dif_before_1d']) if pd.notnull(upData.at[date,'gol_dif_before_1d']) else None,\n",
    "                                   float(upData.at[date,'dj_close']),float(upData.at[date,'dj_MA_5']) if pd.notnull(upData.at[date,'dj_MA_5']) else None ,float(upData.at[date,'dj_MA_60']) if pd.notnull(upData.at[date,'dj_MA_60']) else None,float(upData.at[date,'dj_dif']) if pd.notnull(upData.at[date,'dj_dif']) else None ,float(upData.at[date,'dj_dif_before_1d']) if pd.notnull(upData.at[date,'dj_dif_before_1d']) else None,\n",
    "                                   int(upData.at[date,'bit_change']) if pd.notnull(upData.at[date,'bit_change']) else None,int(upData.at[date,'gol_change']) if pd.notnull(upData.at[date,'gol_change']) else None,int(upData.at[date,'dj_change']) if pd.notnull(upData.at[date,'dj_change']) else None ) )\n",
    "\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima predict custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_predict(df, typeData) :\n",
    "    \n",
    "    if typeData == 'gol' :\n",
    "        orders =(0,2,1)\n",
    "    else :\n",
    "        orders = (1,2,2)\n",
    "        \n",
    "    predictDay = 1\n",
    "    \n",
    "    beforeYear= dt.datetime.now().date().replace(year=dt.datetime.now().year-3)\n",
    "    testDate = dt.datetime.now().date().replace(day=dt.datetime.now().day)\n",
    "    \n",
    "    featureTrain = result_sub.loc[beforeYear:testDate,typeData+'_close']\n",
    "    featureTest = result_sub.loc[testDate:,typeData+'_close']\n",
    "    \n",
    "    arima_model = ARIMA(featureTrain, order=orders)\n",
    "    arima_fit = arima_model.fit(trend='nc', full_output=True, disp=1)\n",
    "    \n",
    "    arima_predict = arima_fit.forecast(steps=predictDay)\n",
    "#     featureTest\n",
    "    \n",
    "    return (arima_predict[0],featureTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "dataList = ['bit','gol','dj']\n",
    "\n",
    "for cols in dataList :\n",
    "    vars()[cols+'_pred'], vars()[cols+'_test'] = arima_predict(upData,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9229.64622161] Series([], Name: bit_close, dtype: float64)\n",
      "[1558.59420264] Series([], Name: gol_close, dtype: float64)\n",
      "[28838.14967678] Series([], Name: dj_close, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "for cols in dataList :\n",
    "    print(vars()[cols+'_pred'],vars()[cols+'_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitXY\n",
    "def splitXY(df, dataType) :\n",
    "    temp_x = df.loc[:,[dataType+'_close', dataType+'_MA_5',dataType+'_MA_60', dataType+'_dif',dataType+'_dif_before_1d']]\n",
    "    temp_y = df.loc[:,dataType+'_change']\n",
    "    return(temp_x, temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = ['bit','gol','dj']\n",
    "\n",
    "for cols in dataList :\n",
    "    vars()[cols+'_x'], vars()[cols+'_y'] = splitXY(upData, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification 확인하기 위해 validation\n",
    "\n",
    "for cols in dataList :\n",
    "    vars()[cols+'_x_train'] = vars()[cols+'_x'].iloc[:-1,:]\n",
    "    vars()[cols+'_y_train'] = vars()[cols+'_y'].iloc[:-1]\n",
    "    \n",
    "    vars()[cols+'_x_test'] = vars()[cols+'_x'].iloc[-1,:]\n",
    "    vars()[cols+'_y_test'] = vars()[cols+'_y'].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier\n",
    "# knn, svm, rfc, xgb, lgb 의 예측값을 확인해서 ensemble 처리\n",
    "\n",
    "# svm은 ㅈㄴ 느려서 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get knn_best\n",
    "def getKnc(x_train,y_train,x_test,kfold) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    knc = KNeighborsClassifier(n_jobs = -1)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_neighbors':np.arange(1,11,2),\n",
    "        'weights':['uniform','distance']\n",
    "    }\n",
    "    n_iter_search=10\n",
    "    knc_rgs = RandomizedSearchCV(knc, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    knc_rgs.fit(x_train, y_train)\n",
    "    \n",
    "    # Random Grid Search 기준으로 Grid Search의 파라미터 값 처리\n",
    "    rgs_best_nei = knc_rgs.best_params_.get('n_neighbors')\n",
    "    rgs_best_weights = knc_rgs.best_params_.get('weights')\n",
    "    \n",
    "    grid_params = {\n",
    "        'n_neighbors':np.arange(rgs_best_nei-2 if rgs_best_nei>2 else 1, rgs_best_nei+4,2),\n",
    "        'weights':rgs_best_weights\n",
    "    }\n",
    "    \n",
    "    n_iter_search=10\n",
    "    knc_gs = GridSearchCV(knc, param_grid=parameters, cv=kfold,scoring='accuracy',verbose=1, n_jobs=-1)\n",
    "\n",
    "    knc_gs.fit(x_train, y_train)\n",
    "    knc_best = knc_gs.best_estimator_\n",
    "    prediction = knc_best.predict(x_test_trans.T)\n",
    "    \n",
    "    # 반환 : 예측값, 배스트 모델값\n",
    "    return (prediction[0],knc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random GridSearch만 적용함..사유는 너무나 느려서, 2중으로 적용해서 결과를 도출해냄\n",
    "# Random Grid Search 도 2번돌리면 뻣는데 뭐지 ?\n",
    "def getSvm(x_train,y_train,x_test,kfold) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    svc = SVC(max_iter=100000)\n",
    "    \n",
    "    parameters = {\n",
    "        'C':np.arange(1,5,0.5),   # np.arange(1,5),\n",
    "        'kernel':['rbf','poly'],\n",
    "        'degree':np.arange(2,5),\n",
    "        'gamma': [0.01,0.1,1,10]\n",
    "    }\n",
    "    n_iter_search=10\n",
    "    svc_rgs = RandomizedSearchCV(svc, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    svc_rgs.fit(x_train, y_train)\n",
    "    \n",
    "    svc_best = svc_rgs.best_estimator_\n",
    "    prediction = svc_best.predict(x_test_trans.T)\n",
    "    \n",
    "    # 반환 : 예측값, 배스트 모델값\n",
    "    return (prediction[0],svc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random GridSearch만 적용함..사유는 너무나 느려서, 2중으로 적용해서 결과를 도출해냄\n",
    "# Random Grid Search 도 2번돌리면 뻣는데 뭐지 ?\n",
    "def getSvm_oldRgs2(x_train,y_train,x_test) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    svc = SVC()\n",
    "    \n",
    "    parameters = {\n",
    "        'C':np.arange(1,10),\n",
    "        'kernel':['rbf','poly','linear'],\n",
    "        'degree':np.arange(2,5),\n",
    "        'gamma': [0.01,0.1,1,10]\n",
    "    }\n",
    "    n_iter_search=10\n",
    "    svc_rgs = RandomizedSearchCV(svc, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    svc_rgs.fit(x_train, y_train)\n",
    "    \n",
    "    # Random Grid Search 기준으로 Grid Search의 파라미터 값 처리\n",
    "    svc_c = svc_rgs.best_params_.get('C')\n",
    "    svc_k = svc_rgs.best_params_.get('kernel')\n",
    "    svc_d = svc_rgs.best_params_.get('degree')\n",
    "    svc_g = svc_rgs.best_params_.get('gamma')\n",
    "    \n",
    "    parameters = {\n",
    "        'C':np.arange(svc_c-1 if svc_c > 1 else 1,svc_c+2),\n",
    "        'kernel':svc_k,\n",
    "        'degree':np.arange(svc_d-1 if svc_d > 1 else 1,svc_d+2),\n",
    "        'gamma': np.arange(svc_g/2,svc*3/2,svc_g/10)\n",
    "    }\n",
    "    \n",
    "#     svc_rgs_tune = GridSearchCV(svc, param_grid=parameters, cv=7,scoring='accuracy', n_jobs=-1)\n",
    "    svc_rgs_tune = RandomizedSearchCV(svc, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    svc_rgs_tune.fit(x_train, y_train)\n",
    "\n",
    "    svc_rgs_tune.fit(x_train, y_train)\n",
    "    svc_best = svc_rgs_tune.best_estimator_\n",
    "    prediction = svc_best.predict(x_test_trans.T)\n",
    "    \n",
    "    # 반환 : 예측값, 배스트 모델값\n",
    "    return (prediction[0],svc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRfc(x_train,y_train,x_test,kfold) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators':np.arange(50,1000,50),\n",
    "        'max_features':np.arange(1,6),\n",
    "        'min_samples_split':np.arange(2,5),\n",
    "        'max_depth':np.arange(2,15)\n",
    "    }\n",
    "    n_iter_search=10\n",
    "    rfc_rgs = RandomizedSearchCV(rfc, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    rfc_rgs.fit(x_train, y_train)\n",
    "    \n",
    "    # Random Grid Search 기준으로 Grid Search의 파라미터 값 처리\n",
    "    rs_ne = rfc_rgs.best_params_.get('n_estimators')\n",
    "    rs_mf = rfc_rgs.best_params_.get('max_features')\n",
    "    rs_de = rfc_rgs.best_params_.get('max_depth')\n",
    "    rs_sp = rfc_rgs.best_params_.get('min_samples_split')\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators':np.arange(rs_ne-1,rs_ne+1),\n",
    "        'max_features':np.arange(rs_mf-1 if rs_mf > 1 else 1,rs_mf+2 if rs_mf < x_train.shape[1] else x_train.shape[1]),\n",
    "        'min_samples_split':np.arange(rs_sp-1 if rs_sp > 2 else 2,rs_sp+2),\n",
    "        'max_depth':np.arange(rs_de-2 if rs_de > 2 else 1,rs_de+3)\n",
    "    }\n",
    "\n",
    "    \n",
    "    rfc_gs = GridSearchCV(rfc, param_grid=parameters, cv=kfold,scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    rfc_gs.fit(x_train, y_train)\n",
    "    rfc_best = rfc_gs.best_estimator_\n",
    "    prediction = rfc_best.predict(x_test_trans.T)\n",
    "    \n",
    "    # 반환 : 예측값, 배스트 모델값\n",
    "    return (prediction[0],rfc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXgbc(x_train,y_train,x_test,kfold) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    xgbc = XGBClassifier(verbosity=1, n_jobs=-1)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators':np.arange(50,1000,50),\n",
    "        'learning_rate':np.arange(0.3,0.01,-0.05),\n",
    "        'max_depth':np.arange(2,10)\n",
    "    }\n",
    "    n_iter_search=10\n",
    "    xgbc_rgs = RandomizedSearchCV(xgbc, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    xgbc_rgs.fit(x_train, y_train)\n",
    "    \n",
    "    # Random Grid Search 기준으로 Grid Search의 파라미터 값 처리\n",
    "    xg_ne = xgbc_rgs.best_params_.get('n_estimators')\n",
    "    xg_lr = xgbc_rgs.best_params_.get('learning_rate')\n",
    "    xg_md = xgbc_rgs.best_params_.get('max_depth')\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators':np.arange(xg_ne-1,xg_ne+1),\n",
    "        'learning_rate':np.arange(xg_lr+0.04,xg_lr-0.05 if xg_lr > 0.05 else 0.01, -0.02),\n",
    "        'max_depth':np.arange(xg_md-2 if xg_md > 4 else 2, xg_md+2)\n",
    "    }\n",
    "\n",
    "    \n",
    "    xgbc_gs = GridSearchCV(xgbc, param_grid=parameters, cv=kfold,scoring='accuracy',verbose=1, n_jobs=-1)\n",
    "\n",
    "    xgbc_gs.fit(x_train, y_train)\n",
    "    xgbc_best = xgbc_gs.best_estimator_\n",
    "    prediction = xgbc_best.predict(x_test_trans.T)\n",
    "    \n",
    "    # 반환 : 예측값, 배스트 모델값\n",
    "    return (prediction[0],xgbc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLgbc(x_train,y_train,x_test,kfold) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    LGB = LGBMClassifier(verbose=1, n_jobs=-1)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators':np.arange(50,1000,50),\n",
    "        'learning_rate':np.arange(0.3,0.01,-0.05),\n",
    "        'max_depth':np.arange(2,20,2)\n",
    "    }\n",
    "    n_iter_search=10\n",
    "    lgbc_rgs = RandomizedSearchCV(LGB, param_distributions=parameters, cv=kfold,\n",
    "                                scoring='accuracy', n_jobs=-1,\n",
    "                                verbose=1,random_state=1234,\n",
    "                                n_iter=n_iter_search)\n",
    "    lgbc_rgs.fit(x_train, y_train)\n",
    "    \n",
    "    # Random Grid Search 기준으로 Grid Search의 파라미터 값 처리\n",
    "    lg_ne = lgbc_rgs.best_params_.get('n_estimators')\n",
    "    lg_lr = lgbc_rgs.best_params_.get('learning_rate')\n",
    "    lg_md = lgbc_rgs.best_params_.get('max_depth')\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators':np.arange(lg_ne-1,lg_ne+1),\n",
    "        'learning_rate':np.arange(lg_lr+0.04,lg_lr-0.05 if lg_lr > 0.05 else 0.01, -0.02),\n",
    "        'max_depth':np.arange(lg_md-2 if lg_md > 4 else 2, lg_md+2)\n",
    "    }\n",
    "\n",
    "    \n",
    "    lgbc_gs = GridSearchCV(LGB, param_grid=parameters, cv=kfold,scoring='accuracy',verbose=1, n_jobs=-1)\n",
    "\n",
    "    lgbc_gs.fit(x_train, y_train)\n",
    "    lgbc_best = lgbc_gs.best_estimator_\n",
    "    prediction = lgbc_best.predict(x_test_trans.T)\n",
    "    \n",
    "    # 반환 : 예측값, 배스트 모델값\n",
    "    return (prediction[0],lgbc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembleVC(knc,svc,rfc,xgbc,lgbc,x_train,y_train,x_test) :\n",
    "    x_test_trans = pd.DataFrame(x_test)\n",
    "    \n",
    "    evc = VotingClassifier(estimators= [('knc',knc),('svc',svc),('rfc',rfc),('xgb',xgbc), ('lgbc',lgbc)],\n",
    "                       voting='hard')\n",
    "    evc.fit(x_train,y_train)\n",
    "    evc_pred = evc.predict(x_test_trans.T)\n",
    "    \n",
    "    return(evc_pred[0], evc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArima(df, dataType) :\n",
    "    \n",
    "    if dataType == 'gol' :\n",
    "        orders =(0,2,1)\n",
    "    else :\n",
    "        orders = (1,2,2)\n",
    "        \n",
    "    \n",
    "    X_train = df.loc[:,dataType+'_close']\n",
    "    \n",
    "    arima_model = ARIMA(X_train, order=orders)\n",
    "    arima_fit = arima_model.fit(trend='nc', full_output=True, disp=1)\n",
    "    \n",
    "    arima_predict = arima_fit.forecast(steps=1)\n",
    "    \n",
    "    return (arima_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitXY\n",
    "def splitXY(df, dataType) :\n",
    "    temp_x = df.loc[:,[dataType+'_close', dataType+'_MA_5',dataType+'_MA_60', dataType+'_dif',dataType+'_dif_before_1d']]\n",
    "    temp_y = df.loc[:,dataType+'_change']\n",
    "    return(temp_x, temp_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 모듈합산 함수 - 자동화를 위해\n",
    "def predict(df,dataType,dateNum) :\n",
    "    # 나중에 날짜 받는걸 만들어야할듯\n",
    "    \n",
    "    # feature, target 분할\n",
    "    tmp_x, tmp_y = splitXY(df, dataType)\n",
    "    \n",
    "    # train, test 분할\n",
    "    tmp_x_train = tmp_x.iloc[:-1,:]\n",
    "    tmp_y_train = tmp_y.iloc[:-1]\n",
    "    tmp_x_test = tmp_x.iloc[-1,:]\n",
    "    #tmp_y_test = tmp_y.iloc[-1]\n",
    "    \n",
    "    # 나중에 데이터 획득 시점을 변경하기 위한 알고리즘\n",
    "    dateList = [upData.index[-1].date() - relativedelta(months=3),\n",
    "                upData.index[-1].date() - relativedelta(years=1),\n",
    "                upData.index[-1].date() - relativedelta(years=2),\n",
    "                upData.index[-1].date() - relativedelta(years=3),\n",
    "                upData.index[-1].date() - relativedelta(years=5)]\n",
    "    \n",
    "    # 같은 데이터를 하기위해 kfold 조정\n",
    "    kfold = KFold(n_splits=7, random_state=0,shuffle = True)\n",
    "    \n",
    "    # 분할 된 데이터로 각 모듈 작업\n",
    "    pred_knc, knc_best = getKnc(tmp_x_train.loc[dateList[dateNum]:,:], tmp_y_train.loc[dateList[dateNum]:],tmp_x_test,kfold)\n",
    "    pred_svc, svc_best = getSvm(tmp_x_train.loc[dateList[dateNum]:,:], tmp_y_train.loc[dateList[dateNum]:],tmp_x_test,kfold)\n",
    "    pred_rfc, rfc_best = getRfc(tmp_x_train.loc[dateList[dateNum]:,:], tmp_y_train.loc[dateList[dateNum]:],tmp_x_test,kfold)\n",
    "    pred_xgbc, xgbc_best = getXgbc(tmp_x_train.loc[dateList[dateNum]:,:], tmp_y_train.loc[dateList[dateNum]:],tmp_x_test,kfold)\n",
    "    pred_lgbc, lgbc_best = getLgbc(tmp_x_train.loc[dateList[dateNum]:,:], tmp_y_train.loc[dateList[dateNum]:],tmp_x_test,kfold)\n",
    "    \n",
    "    # 5가지의 모듈 값을 기준으로 ensemble voting 실시\n",
    "    pred_vote, vote_best = ensembleVC(knc_best,svc_best,rfc_best,xgbc_best,lgbc_best,\n",
    "                                      tmp_x_train.loc[dateList[dateNum]:,:], tmp_y_train.loc[dateList[dateNum]:],\n",
    "                                      tmp_x_test)\n",
    "    \n",
    "    # arima_predict 값\n",
    "    pred_arima = getArima(tmp_x_train.loc[dateList[dateNum]:,:], dataType)\n",
    "    \n",
    "    return(pred_vote, pred_knc, pred_svc, pred_rfc, pred_xgbc, pred_lgbc, pred_arima)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 전달을 못해서 임시 폐기\n",
    "\n",
    "def predict_all(df,dateNum) :\n",
    "    dataList = ['bit','gol','dj']\n",
    "    # 각 dataFrame 선언\n",
    "    for d in dataList :\n",
    "        vars()[d+'_pred'] = pd.DataFrame([])\n",
    "    \n",
    "    # 각 data에 대해서 데이터 연산 구하기\n",
    "    for d in dataList :\n",
    "        tmp_vote, tmp_knc,tmp_svc,tmp_rfc, tmp_xgbc,tmp_lgbc,tmp_arima = predict(df,d,dateNum)\n",
    "        vars()[d+'_pred'] = vars()[d+'_pred'].append({'vote':tmp_vote,'knc':tmp_knc,'svc':tmp_svc,'rfc':tmp_rfc,'xgbc':tmp_xgbc,'lgbc':tmp_lgbc,'arima':tmp_arima[0] },ignore_index=True)\n",
    "    \n",
    "    return (bit_pred, gol_pred, dj_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.2s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:241: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    4.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 60 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:   15.3s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    6.6s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   53.5s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.4s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    2.3s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:241: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.3s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    4.5s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 60 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:   14.5s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   28.2s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  2.7min finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.3s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   10.1s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    0.2s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    4.1s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 24 candidates, totalling 168 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:   16.0s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   25.6s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  2.5min finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.8s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    0.8s finished\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "C:\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         arima  knc  lgbc  rfc  svc  vote  xgbc\n",
       " 0  9249.545295 -1.0   1.0  1.0  1.0   1.0   1.0,\n",
       "          arima  knc  lgbc  rfc  svc  vote  xgbc\n",
       " 0  1559.070192  1.0   1.0  1.0  1.0   1.0   1.0,\n",
       "           arima  knc  lgbc  rfc  svc  vote  xgbc\n",
       " 0  28817.479088  1.0   1.0  1.0  1.0   1.0  -1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList = ['bit','gol','dj']\n",
    "# 각 dataFrame 선언\n",
    "for d in dataList :\n",
    "    vars()[d+'_pred'] = pd.DataFrame([])\n",
    "\n",
    "# 각 data에 대해서 데이터 연산 구하기\n",
    "for d in dataList :\n",
    "    tmp_vote, tmp_knc,tmp_svc,tmp_rfc, tmp_xgbc,tmp_lgbc,tmp_arima = predict(upData,d,0)\n",
    "    vars()[d+'_pred'] = vars()[d+'_pred'].append({'vote':tmp_vote,'knc':tmp_knc,'svc':tmp_svc,'rfc':tmp_rfc,'xgbc':tmp_xgbc,'lgbc':tmp_lgbc,'arima':tmp_arima[0] },ignore_index=True)\n",
    "\n",
    "bit_pred, gol_pred, dj_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 DB에 데이터 채우기\n",
    "\n",
    "# db 커넥션 연결\n",
    "conn = pymysql.connect(host='localhost', port=3306,\n",
    "                       user='acorn12', passwd='acorn12', db='acorn', charset='utf8')\n",
    "\n",
    "# conn = pymysql.connect(host='localhost', port=3306,\n",
    "#                        user='flo', passwd='flo', db='db', charset='utf8')\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = 'SELECT IFNULL(MAX(pc_date),\"2013-01-01\") FROM pred_clf '\n",
    "        \n",
    "        cursor.execute(sql)\n",
    "        \n",
    "        rows = cursor.fetchone()\n",
    "        lastDate = rows[0]\n",
    "        \n",
    "        # db에 기록된 가장 최근값과 오늘의 날짜 반납( 이 기준으로 db에서 가져옴)\n",
    "        \n",
    "        recentlyDate = pd.to_datetime(lastDate).date()\n",
    "        recentlyDate += dt.timedelta(days=1) # 하루 추가하기(다음날로 확인하는 거)\n",
    "        \n",
    "        if recentlyDate < upData.index[-1] :\n",
    "            sql = 'INSERT INTO pred_clf(pc_date, pc_bit_arima, pc_gol_arima, pc_dj_arima, '\n",
    "            sql += 'pc_bit_vote, pc_bit_knc, pc_bit_svc, pc_bit_rfc, pc_bit_xgbc, pc_bit_lgbc, '\n",
    "            sql += 'pc_gol_vote, pc_gol_knc, pc_gol_svc, pc_gol_rfc, pc_gol_xgbc, pc_gol_lgbc, '\n",
    "            sql += 'pc_dj_vote, pc_dj_knc, pc_dj_svc, pc_dj_rfc, pc_dj_xgbc, pc_dj_lgbc) '\n",
    "            sql += 'VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) '\n",
    "\n",
    "            cursor.execute(sql,(upData.index[-1].date(), float(bit_pred['arima']), float(gol_pred['arima']), float(dj_pred['arima']),\n",
    "                               int(bit_pred['vote']), int(bit_pred['knc']), int(bit_pred['svc']), int(bit_pred['rfc']), int(bit_pred['xgbc']), int(bit_pred['lgbc']),\n",
    "                               int(gol_pred['vote']), int(gol_pred['knc']), int(gol_pred['svc']), int(gol_pred['rfc']), int(gol_pred['xgbc']), int(gol_pred['lgbc']),\n",
    "                               int(dj_pred['vote']), int(dj_pred['knc']), int(dj_pred['svc']), int(dj_pred['rfc']), int(dj_pred['xgbc']), int(dj_pred['lgbc']) ) )\n",
    "\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
