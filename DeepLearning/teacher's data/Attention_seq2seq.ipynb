{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention 신경망 구현 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* konlp 설치 관련해서 OS관련해서 추가 설치들이 필요하니, 관련 내용 잘 확인 필요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/img_41.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tag 여러 종류  \n",
    "  - JHannanum is a morphological analyzer and POS tagger written in Java, and developed by the Semantic Web Research Center (SWRC) at KAIST since 1999   \n",
    "  - Kkma is a morphological analyzer and natural language processing system written in Java, developed by the Intelligent Data Systems (IDS) Laboratory at SNU.    \n",
    "  - KOMORAN is a relatively new open source Korean morphological analyzer written in Java, developed by Shineware, since 2013.    \n",
    "  - MeCab, originally a Japanese morphological analyzer and POS tagger developed by the Graduate School of Informatics in Kyoto University, was modified to MeCab-ko by the Eunjeon Project to adapt to the Korean language.    \n",
    "  - Open Korean Text is an open source Korean tokenizer written in Scala, developed by Will Hohyon Ryu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "import jpype\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 konlp가 제대로 설치 되었는지 확인을 위해서...\n",
    "# 위의 konlpy만 해서는 제대로 설치 되었는지 확인이 안 될 수 있음!!!!\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "NUM_WORDS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # 입력이 one-hot-encdoing 형식으로 들어오면 embedding을 수행을 먼저\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n",
    "        # 그리고 LSTM에서 hidden state을 출력으로 던져주어야 이것을 활용해서 return을 활용할 수 있다...\n",
    "        # return_sequence=True : 디코더에서 나오는 것 하나하나 알아야 하기에...\n",
    "        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n",
    "        # return_sequences = True -> attention 하기 위해서\n",
    "\n",
    "    # 인코더의 경우에는 입력이 들어오면 이것을 바탕으로 히든, 셀 스테이트를 하도록 ...\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.emb(x)\n",
    "        # h,c는 test를 할 경우에는 다음으로 넘겨 주어야 forward  로 계산을 하면서 나갈 수 있으니..\n",
    "        H, h, c = self.lstm(x)\n",
    "        return H, h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n",
    "        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n",
    "        \n",
    "        #****Attention을 추가함!!!! \n",
    "        self.att = tf.keras.layers.Attention()\n",
    "        \n",
    "        # 최종 단어 단에서 어떤 것을 할 것인지..선택..\n",
    "        self.dense = tf.keras.layers.Dense(NUM_WORDS, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        # ***처음 들어오는 인코더 단에서 넘어오는 것들을 받고,,\n",
    "        x, s0, c0, H = inputs\n",
    "        x = self.emb(x)\n",
    "        # ****S는 hidden state를 모두 모아둔 부분..--> 쿼리로 사용을 할 것임....--->하나 앞선 시간을 사용을 해서..\n",
    "        S, h, c = self.lstm(x, initial_state=[s0, c0])\n",
    "        # ***쿼리로 사용을 할 것임....--->하나 앞선 시간을 사용을 해서..(1차원을 3차원으로 확장) & 마지막 히든은 제외...해서 :-1까지..\n",
    "        S_ = tf.concat([s0[:, tf.newaxis, :], S[:, :-1, :]], axis=1)\n",
    "        # ****키와 value를 계산하고,,,\n",
    "        A = self.att([S_, H])\n",
    "        y = tf.concat([S, A], axis=-1)\n",
    "        \n",
    "        return self.dense(y), h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 참고 사항   \n",
    " - super : 자식클래스 내에서 코드에서도 부모클래스를 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(tf.keras.Model):\n",
    "    def __init__(self, sos, eos):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        # 1) 가장 기본적으로 필요한 Encoder, Deoder, sos, eos에 관련된 부분을 지정을 함!!!!\n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "        self.sos = sos\n",
    "        self.eos = eos\n",
    "    \n",
    "    # 연결에서 구성 --> 학습을 위해서는 입력/출력 모두 알아야 하기에 x,y = input으로 받음\n",
    "    # 그리고 디코더에 입력을 넣어주어야 하기에..\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "       # (학습 과정)\n",
    "        if training is True:\n",
    "            # 학습을 위해서는 입력/출력 모두 알아야 하기에 x,y = input으로 받음\n",
    "            # 그리고 디코더에 입력을 넣어주어야 하기에..\n",
    "            x, y = inputs\n",
    "            # encoder에 입력  x를 넣어서 나온 hidden state, cell  (LSTM으로 구현이 되어서..)\n",
    "            H, h, c = self.enc(x)\n",
    "            # 최종 출력 y를 하도록...\n",
    "            y, _, _ = self.dec((y, h, c, H))\n",
    "            return y\n",
    "        # (Test 과정) --> 그러니 정답  y는 없음..\n",
    "        else:\n",
    "            x = inputs\n",
    "            H, h, c = self.enc(x)\n",
    "            # 뒤에 디커더 부분에 입력을 넣어 주는 부분이 달라지게 된다!!!! --> sos  를 넣어준다.\n",
    "            y = tf.convert_to_tensor(self.sos)\n",
    "            y = tf.reshape(y, (1, 1))\n",
    "\n",
    "            # 최대 seq는 64길이까지만..\n",
    "            seq = tf.TensorArray(tf.int32, 64)\n",
    "            \n",
    "            # tf의  for loop으로 사용을 해서 최대 64까지 \n",
    "            for idx in tf.range(64):\n",
    "                # for 에서 처음에는 처음으로 만들어준 sos를 decoder에 입력으로 넣어주고 --> self.dec(y,h,c,H)을 해서\n",
    "                # 출력인 y와 hidden state, cell state를 출력으로 준다.\n",
    "                y, h, c = self.dec([y, h, c, H])\n",
    "                # 가장 큰 y값에 대한 index를 얻어오게 되는 과정\n",
    "                y = tf.cast(tf.argmax(y, axis=-1), dtype=tf.int32)\n",
    "                # reshape를 하면서 batch를 사용을 하기 위해서...\n",
    "                y = tf.reshape(y, (1, 1))\n",
    "                # seq를 하나씩 받으면서 처리하기 위해서...\n",
    "                seq = seq.write(idx, y)\n",
    "                # eos일 때 까지 for lopp순환\n",
    "                if y == self.eos:\n",
    "                    break\n",
    "            # \n",
    "            return tf.reshape(seq.stack(), (1, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습, 테스트 루프 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/img_40.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement training loop\n",
    "@tf.function\n",
    "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    # 마지맞 eos는 있고, 처음 sos 는 없는 것...\n",
    "    output_labels = labels[:, 1:]\n",
    "    # 처음 sos는 포함이 되고, 마지막 eos는 빼고...\n",
    "    shifted_labels = labels[:, :-1]\n",
    "    # 그래서 위의 시프트 된 것들이 아래의 model의 학습 과정에 들어가게 된다!!!!!\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 위의 output_labels, shifted_labels 이 들어가게 된다...\n",
    "        predictions = model([inputs, shifted_labels], training=True)\n",
    "        loss = loss_object(output_labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(output_labels, predictions)\n",
    "\n",
    "# Implement algorithm test\n",
    "@tf.function\n",
    "def test_step(model, inputs):\n",
    "    return model(inputs, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>아이스아메리카노 하나요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>테이크아웃하실 건가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>저 카푸치노로 주문할게요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    아이스아메리카노 하나요\n",
       "0   테이크아웃하실 건가요?\n",
       "1  저 카푸치노로 주문할게요"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_file_path ='content/chatbot_data_sample.csv'\n",
    "\n",
    "newData = pd.read_csv(dataset_file_path)\n",
    "newData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.to_csv('content/chatbot_data_sample_cvt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-A 형태의 데이터 셋... ---> 본인들이 구성을 하시면 됩니다!!!!\n",
    "# cafe.xlsx를 바탕으로 한 것이고, 다른 데이터 셋도 구할 수 있습니다!!!!!\n",
    "dataset_file = 'content/chatbot_data_sample.csv' # acquired from 'http://www.aihub.or.kr' and modified\n",
    "okt = Okt()\n",
    "\n",
    "with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    # 한 줄에 대한 형태소 분석 수행-->morphs\n",
    "    seq = [' '.join(okt.morphs(line)) for line in lines]\n",
    "\n",
    "# 원본 데이터에서 질문과 답변에 대한 것들을 분리...한줄 한줄 건너서 있으니...처음에 질문부터이니 0부터 질문, 홀수가 답변--> 하나씩 건너서..\n",
    "questions = seq[::2]\n",
    "answers = ['\\t ' + lines for lines in seq[1::2]]\n",
    "\n",
    "num_sample = len(questions)\n",
    "\n",
    "# 질문을 보고 한 번 데이터 셋을 섞어준다..\n",
    "perm = list(range(num_sample))\n",
    "random.seed(0)\n",
    "random.shuffle(perm)\n",
    "# 섞으면서 train/ test로 구분을 하기 위한 것..\n",
    "train_q = list()\n",
    "train_a = list()\n",
    "test_q = list()\n",
    "test_a = list()\n",
    "\n",
    "# 질문과 답변에 대한 것을 돌면서...\n",
    "for idx, qna in enumerate(zip(questions, answers)):\n",
    "    q, a = qna\n",
    "    # 5/1은 test, 5/4는 train\n",
    "    if perm[idx] > num_sample//5:\n",
    "        train_q.append(q)\n",
    "        train_a.append(a)\n",
    "    else:\n",
    "        test_q.append(q)\n",
    "        test_a.append(a)\n",
    "\n",
    "# 문장에서 짤라주는 것에 대한 세팅...\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS,\n",
    "                                                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "tokenizer.fit_on_texts(train_q + train_a)\n",
    "\n",
    "train_q_seq = tokenizer.texts_to_sequences(train_q)\n",
    "train_a_seq = tokenizer.texts_to_sequences(train_a)\n",
    "\n",
    "test_q_seq = tokenizer.texts_to_sequences(test_q)\n",
    "test_a_seq = tokenizer.texts_to_sequences(test_a)\n",
    "\n",
    "# 입력은 뒤로...패딩..\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(train_q_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=64)\n",
    "# 출력은 앞에로 패딩..\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(train_a_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=65)\n",
    "\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(test_q_seq,\n",
    "                                                       value=0,\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=64)\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(test_a_seq,\n",
    "                                                       value=0,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=65)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(1).prefetch(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 환경 정의\n",
    "### 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Seq2seq(sos=tokenizer.word_index['\\t'],\n",
    "                eos=tokenizer.word_index['\\n'])\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define performance metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 루프 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.8942363262176514, Accuracy: 83.07878875732422\n",
      "Epoch 2, Loss: 0.6981980800628662, Accuracy: 90.3900375366211\n",
      "Epoch 3, Loss: 0.6010884046554565, Accuracy: 90.46052551269531\n",
      "Epoch 4, Loss: 0.5669671297073364, Accuracy: 91.18498992919922\n",
      "Epoch 5, Loss: 0.5512641072273254, Accuracy: 91.16541290283203\n",
      "Epoch 6, Loss: 0.5374450087547302, Accuracy: 91.10667419433594\n",
      "Epoch 7, Loss: 0.5276485085487366, Accuracy: 91.15757751464844\n",
      "Epoch 8, Loss: 0.5301676988601685, Accuracy: 91.15757751464844\n",
      "Epoch 9, Loss: 0.5062738656997681, Accuracy: 91.23590087890625\n",
      "Epoch 10, Loss: 0.494384229183197, Accuracy: 91.38471221923828\n",
      "Epoch 11, Loss: 0.4773052930831909, Accuracy: 91.51002502441406\n",
      "Epoch 12, Loss: 0.4709937870502472, Accuracy: 91.69408416748047\n",
      "Epoch 13, Loss: 0.4565075635910034, Accuracy: 91.98778533935547\n",
      "Epoch 14, Loss: 0.4497081935405731, Accuracy: 92.23841094970703\n",
      "Epoch 15, Loss: 0.44294074177742004, Accuracy: 92.40287780761719\n",
      "Epoch 16, Loss: 0.43623483180999756, Accuracy: 92.45770263671875\n",
      "Epoch 17, Loss: 0.429127961397171, Accuracy: 92.56343841552734\n",
      "Epoch 18, Loss: 0.4270467162132263, Accuracy: 92.61434936523438\n",
      "Epoch 19, Loss: 0.4172070622444153, Accuracy: 92.70832824707031\n",
      "Epoch 20, Loss: 0.4142557382583618, Accuracy: 92.73966217041016\n",
      "Epoch 21, Loss: 0.4042547047138214, Accuracy: 92.73966217041016\n",
      "Epoch 22, Loss: 0.40212810039520264, Accuracy: 92.84539031982422\n",
      "Epoch 23, Loss: 0.3945654332637787, Accuracy: 92.85713958740234\n",
      "Epoch 24, Loss: 0.3902689814567566, Accuracy: 92.92371368408203\n",
      "Epoch 25, Loss: 0.38820886611938477, Accuracy: 92.94329071044922\n",
      "Epoch 26, Loss: 0.37994542717933655, Accuracy: 92.96678924560547\n",
      "Epoch 27, Loss: 0.37331777811050415, Accuracy: 93.0177001953125\n",
      "Epoch 28, Loss: 0.37247106432914734, Accuracy: 93.06077575683594\n",
      "Epoch 29, Loss: 0.3694360852241516, Accuracy: 93.06861114501953\n",
      "Epoch 30, Loss: 0.37134870886802673, Accuracy: 93.12734985351562\n",
      "Epoch 31, Loss: 0.364875465631485, Accuracy: 93.17434692382812\n",
      "Epoch 32, Loss: 0.3568105101585388, Accuracy: 93.18609619140625\n",
      "Epoch 33, Loss: 0.35518109798431396, Accuracy: 93.2135009765625\n",
      "Epoch 34, Loss: 0.34913355112075806, Accuracy: 93.23308563232422\n",
      "Epoch 35, Loss: 0.345675528049469, Accuracy: 93.28791046142578\n",
      "Epoch 36, Loss: 0.3432949185371399, Accuracy: 93.3192367553711\n",
      "Epoch 37, Loss: 0.3374132513999939, Accuracy: 93.33489990234375\n",
      "Epoch 38, Loss: 0.3385811448097229, Accuracy: 93.40538787841797\n",
      "Epoch 39, Loss: 0.33671659231185913, Accuracy: 93.47587585449219\n",
      "Epoch 40, Loss: 0.3310411274433136, Accuracy: 93.44063568115234\n",
      "Epoch 41, Loss: 0.32427388429641724, Accuracy: 93.51112365722656\n",
      "Epoch 42, Loss: 0.31966087222099304, Accuracy: 93.57769775390625\n",
      "Epoch 43, Loss: 0.31473976373672485, Accuracy: 93.59727478027344\n",
      "Epoch 44, Loss: 0.31528016924858093, Accuracy: 93.62468719482422\n",
      "Epoch 45, Loss: 0.30916827917099, Accuracy: 93.67559814453125\n",
      "Epoch 46, Loss: 0.30398476123809814, Accuracy: 93.69517517089844\n",
      "Epoch 47, Loss: 0.3001669943332672, Accuracy: 93.73825073242188\n",
      "Epoch 48, Loss: 0.2975192368030548, Accuracy: 93.7891616821289\n",
      "Epoch 49, Loss: 0.2904578149318695, Accuracy: 93.83223724365234\n",
      "Epoch 50, Loss: 0.2842435836791992, Accuracy: 93.92230224609375\n",
      "Epoch 51, Loss: 0.28065431118011475, Accuracy: 93.8870620727539\n",
      "Epoch 52, Loss: 0.2756808400154114, Accuracy: 93.91838836669922\n",
      "Epoch 53, Loss: 0.2731134593486786, Accuracy: 94.05936431884766\n",
      "Epoch 54, Loss: 0.26566576957702637, Accuracy: 94.13768768310547\n",
      "Epoch 55, Loss: 0.2622857391834259, Accuracy: 94.28257751464844\n",
      "Epoch 56, Loss: 0.2525734603404999, Accuracy: 94.25908660888672\n",
      "Epoch 57, Loss: 0.24991551041603088, Accuracy: 94.4744644165039\n",
      "Epoch 58, Loss: 0.2443428635597229, Accuracy: 94.53321075439453\n",
      "Epoch 59, Loss: 0.23899582028388977, Accuracy: 94.64286041259766\n",
      "Epoch 60, Loss: 0.23295767605304718, Accuracy: 94.75251007080078\n",
      "Epoch 61, Loss: 0.229085773229599, Accuracy: 94.85823822021484\n",
      "Epoch 62, Loss: 0.22051355242729187, Accuracy: 94.96788787841797\n",
      "Epoch 63, Loss: 0.21721115708351135, Accuracy: 95.14411163330078\n",
      "Epoch 64, Loss: 0.21064652502536774, Accuracy: 95.26158905029297\n",
      "Epoch 65, Loss: 0.20839160680770874, Accuracy: 95.36732482910156\n",
      "Epoch 66, Loss: 0.2017899453639984, Accuracy: 95.43389892578125\n",
      "Epoch 67, Loss: 0.19424758851528168, Accuracy: 95.5474624633789\n",
      "Epoch 68, Loss: 0.18869397044181824, Accuracy: 95.72760009765625\n",
      "Epoch 69, Loss: 0.18049685657024384, Accuracy: 95.94297790527344\n",
      "Epoch 70, Loss: 0.1763371378183365, Accuracy: 96.07612609863281\n",
      "Epoch 71, Loss: 0.1711992472410202, Accuracy: 96.2288589477539\n",
      "Epoch 72, Loss: 0.16495618224143982, Accuracy: 96.27193450927734\n",
      "Epoch 73, Loss: 0.15919525921344757, Accuracy: 96.42073822021484\n",
      "Epoch 74, Loss: 0.15414740145206451, Accuracy: 96.5734634399414\n",
      "Epoch 75, Loss: 0.14930102229118347, Accuracy: 96.64787292480469\n",
      "Epoch 76, Loss: 0.14521487057209015, Accuracy: 96.82017517089844\n",
      "Epoch 77, Loss: 0.14102746546268463, Accuracy: 96.80842590332031\n",
      "Epoch 78, Loss: 0.13559287786483765, Accuracy: 96.90632629394531\n",
      "Epoch 79, Loss: 0.12958742678165436, Accuracy: 97.11387634277344\n",
      "Epoch 80, Loss: 0.12618830800056458, Accuracy: 97.19611358642578\n",
      "Epoch 81, Loss: 0.11999852955341339, Accuracy: 97.40757751464844\n",
      "Epoch 82, Loss: 0.11632608622312546, Accuracy: 97.54463958740234\n",
      "Epoch 83, Loss: 0.11083785444498062, Accuracy: 97.54463958740234\n",
      "Epoch 84, Loss: 0.10834981501102448, Accuracy: 97.66212463378906\n",
      "Epoch 85, Loss: 0.10117931663990021, Accuracy: 97.76786041259766\n",
      "Epoch 86, Loss: 0.098223477602005, Accuracy: 97.83834838867188\n",
      "Epoch 87, Loss: 0.0919535905122757, Accuracy: 98.02239990234375\n",
      "Epoch 88, Loss: 0.08795668184757233, Accuracy: 98.13988494873047\n",
      "Epoch 89, Loss: 0.0838470607995987, Accuracy: 98.22994995117188\n",
      "Epoch 90, Loss: 0.08021827787160873, Accuracy: 98.35134887695312\n",
      "Epoch 91, Loss: 0.07725938409566879, Accuracy: 98.44924926757812\n",
      "Epoch 92, Loss: 0.07285617291927338, Accuracy: 98.57064819335938\n",
      "Epoch 93, Loss: 0.06807871162891388, Accuracy: 98.63721466064453\n",
      "Epoch 94, Loss: 0.0664675384759903, Accuracy: 98.71162414550781\n",
      "Epoch 95, Loss: 0.06176947057247162, Accuracy: 98.74686431884766\n",
      "Epoch 96, Loss: 0.05922554433345795, Accuracy: 98.86042785644531\n",
      "Epoch 97, Loss: 0.056895457208156586, Accuracy: 98.98182678222656\n",
      "Epoch 98, Loss: 0.05394934117794037, Accuracy: 99.02881622314453\n",
      "Epoch 99, Loss: 0.05138387531042099, Accuracy: 99.0718994140625\n",
      "Epoch 100, Loss: 0.048780910670757294, Accuracy: 99.11888885498047\n",
      "Epoch 101, Loss: 0.04709748923778534, Accuracy: 99.22854614257812\n",
      "Epoch 102, Loss: 0.04472843557596207, Accuracy: 99.27944946289062\n",
      "Epoch 103, Loss: 0.04185623303055763, Accuracy: 99.29119873046875\n",
      "Epoch 104, Loss: 0.03982740268111229, Accuracy: 99.32252502441406\n",
      "Epoch 105, Loss: 0.037793297320604324, Accuracy: 99.32252502441406\n",
      "Epoch 106, Loss: 0.0361061654984951, Accuracy: 99.41651153564453\n",
      "Epoch 107, Loss: 0.03439231961965561, Accuracy: 99.43217468261719\n",
      "Epoch 108, Loss: 0.032830432057380676, Accuracy: 99.49483489990234\n",
      "Epoch 109, Loss: 0.03119698539376259, Accuracy: 99.51441192626953\n",
      "Epoch 110, Loss: 0.03057844750583172, Accuracy: 99.53791046142578\n",
      "Epoch 111, Loss: 0.028428375720977783, Accuracy: 99.56532287597656\n",
      "Epoch 112, Loss: 0.026895571500062943, Accuracy: 99.60448455810547\n",
      "Epoch 113, Loss: 0.025450093671679497, Accuracy: 99.63972473144531\n",
      "Epoch 114, Loss: 0.024666782468557358, Accuracy: 99.63581085205078\n",
      "Epoch 115, Loss: 0.023689551278948784, Accuracy: 99.68280029296875\n",
      "Epoch 116, Loss: 0.0221127737313509, Accuracy: 99.706298828125\n",
      "Epoch 117, Loss: 0.021592799574136734, Accuracy: 99.72979736328125\n",
      "Epoch 118, Loss: 0.019956132397055626, Accuracy: 99.71804809570312\n",
      "Epoch 119, Loss: 0.019521145150065422, Accuracy: 99.75328826904297\n",
      "Epoch 120, Loss: 0.018685104325413704, Accuracy: 99.78462219238281\n",
      "Epoch 121, Loss: 0.017868174239993095, Accuracy: 99.76895141601562\n",
      "Epoch 122, Loss: 0.017106901854276657, Accuracy: 99.80419921875\n",
      "Epoch 123, Loss: 0.016702784225344658, Accuracy: 99.81202697753906\n",
      "Epoch 124, Loss: 0.016172634437680244, Accuracy: 99.80811309814453\n",
      "Epoch 125, Loss: 0.015185794793069363, Accuracy: 99.80811309814453\n",
      "Epoch 126, Loss: 0.014802728779613972, Accuracy: 99.83943939208984\n",
      "Epoch 127, Loss: 0.01419849880039692, Accuracy: 99.85118865966797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128, Loss: 0.014338133856654167, Accuracy: 99.81202697753906\n",
      "Epoch 129, Loss: 0.013480021618306637, Accuracy: 99.82377624511719\n",
      "Epoch 130, Loss: 0.012573431245982647, Accuracy: 99.84727478027344\n",
      "Epoch 131, Loss: 0.012145976535975933, Accuracy: 99.8629379272461\n",
      "Epoch 132, Loss: 0.01172414980828762, Accuracy: 99.87860107421875\n",
      "Epoch 133, Loss: 0.011619447730481625, Accuracy: 99.86685180664062\n",
      "Epoch 134, Loss: 0.011503302492201328, Accuracy: 99.87468719482422\n",
      "Epoch 135, Loss: 0.011638503521680832, Accuracy: 99.85902404785156\n",
      "Epoch 136, Loss: 0.010980427265167236, Accuracy: 99.8942642211914\n",
      "Epoch 137, Loss: 0.011055915616452694, Accuracy: 99.85118865966797\n",
      "Epoch 138, Loss: 0.009818525053560734, Accuracy: 99.88252258300781\n",
      "Epoch 139, Loss: 0.009315583854913712, Accuracy: 99.91384887695312\n",
      "Epoch 140, Loss: 0.009168610908091068, Accuracy: 99.87860107421875\n",
      "Epoch 141, Loss: 0.008979473263025284, Accuracy: 99.88252258300781\n",
      "Epoch 142, Loss: 0.00860064197331667, Accuracy: 99.8942642211914\n",
      "Epoch 143, Loss: 0.008759114891290665, Accuracy: 99.89035034179688\n",
      "Epoch 144, Loss: 0.008673288859426975, Accuracy: 99.90601348876953\n",
      "Epoch 145, Loss: 0.007887735962867737, Accuracy: 99.88643646240234\n",
      "Epoch 146, Loss: 0.007983392104506493, Accuracy: 99.88643646240234\n",
      "Epoch 147, Loss: 0.007641599513590336, Accuracy: 99.89035034179688\n",
      "Epoch 148, Loss: 0.007206861861050129, Accuracy: 99.902099609375\n",
      "Epoch 149, Loss: 0.006834312342107296, Accuracy: 99.89818572998047\n",
      "Epoch 150, Loss: 0.006808541715145111, Accuracy: 99.8942642211914\n",
      "Epoch 151, Loss: 0.006399147678166628, Accuracy: 99.92167663574219\n",
      "Epoch 152, Loss: 0.00646083801984787, Accuracy: 99.89818572998047\n",
      "Epoch 153, Loss: 0.006368724163621664, Accuracy: 99.9099349975586\n",
      "Epoch 154, Loss: 0.006322055589407682, Accuracy: 99.91776275634766\n",
      "Epoch 155, Loss: 0.006152122747153044, Accuracy: 99.91776275634766\n",
      "Epoch 156, Loss: 0.006059338338673115, Accuracy: 99.92559814453125\n",
      "Epoch 157, Loss: 0.0057715498842298985, Accuracy: 99.90601348876953\n",
      "Epoch 158, Loss: 0.005494991317391396, Accuracy: 99.91776275634766\n",
      "Epoch 159, Loss: 0.005628642160445452, Accuracy: 99.89818572998047\n",
      "Epoch 160, Loss: 0.005458897911012173, Accuracy: 99.90601348876953\n",
      "Epoch 161, Loss: 0.005251717753708363, Accuracy: 99.91776275634766\n",
      "Epoch 162, Loss: 0.005266621708869934, Accuracy: 99.91776275634766\n",
      "Epoch 163, Loss: 0.005227020010352135, Accuracy: 99.90601348876953\n",
      "Epoch 164, Loss: 0.0053278678096830845, Accuracy: 99.90601348876953\n",
      "Epoch 165, Loss: 0.005162290763109922, Accuracy: 99.9099349975586\n",
      "Epoch 166, Loss: 0.00516078295186162, Accuracy: 99.90601348876953\n",
      "Epoch 167, Loss: 0.005031774751842022, Accuracy: 99.91384887695312\n",
      "Epoch 168, Loss: 0.004941442981362343, Accuracy: 99.91776275634766\n",
      "Epoch 169, Loss: 0.004999528639018536, Accuracy: 99.9099349975586\n",
      "Epoch 170, Loss: 0.004678420722484589, Accuracy: 99.91776275634766\n",
      "Epoch 171, Loss: 0.004517624154686928, Accuracy: 99.91384887695312\n",
      "Epoch 172, Loss: 0.004777620546519756, Accuracy: 99.902099609375\n",
      "Epoch 173, Loss: 0.004631708841770887, Accuracy: 99.9099349975586\n",
      "Epoch 174, Loss: 0.0043446775525808334, Accuracy: 99.91384887695312\n",
      "Epoch 175, Loss: 0.004213494248688221, Accuracy: 99.90601348876953\n",
      "Epoch 176, Loss: 0.004309454001486301, Accuracy: 99.89818572998047\n",
      "Epoch 177, Loss: 0.004112444818019867, Accuracy: 99.93342590332031\n",
      "Epoch 178, Loss: 0.004148333333432674, Accuracy: 99.902099609375\n",
      "Epoch 179, Loss: 0.0039724307134747505, Accuracy: 99.92559814453125\n",
      "Epoch 180, Loss: 0.004204839002341032, Accuracy: 99.91384887695312\n",
      "Epoch 181, Loss: 0.003919620998203754, Accuracy: 99.9099349975586\n",
      "Epoch 182, Loss: 0.003962796181440353, Accuracy: 99.8942642211914\n",
      "Epoch 183, Loss: 0.004051256459206343, Accuracy: 99.902099609375\n",
      "Epoch 184, Loss: 0.0038536826614290476, Accuracy: 99.91384887695312\n",
      "Epoch 185, Loss: 0.003986636642366648, Accuracy: 99.9099349975586\n",
      "Epoch 186, Loss: 0.003673241473734379, Accuracy: 99.92167663574219\n",
      "Epoch 187, Loss: 0.0035661968868225813, Accuracy: 99.9099349975586\n",
      "Epoch 188, Loss: 0.0037602519150823355, Accuracy: 99.902099609375\n",
      "Epoch 189, Loss: 0.003384313080459833, Accuracy: 99.91384887695312\n",
      "Epoch 190, Loss: 0.003624367294833064, Accuracy: 99.9099349975586\n",
      "Epoch 191, Loss: 0.003717359621077776, Accuracy: 99.90601348876953\n",
      "Epoch 192, Loss: 0.0035344548523426056, Accuracy: 99.92167663574219\n",
      "Epoch 193, Loss: 0.0036376549396663904, Accuracy: 99.89818572998047\n",
      "Epoch 194, Loss: 0.0037914530839771032, Accuracy: 99.92559814453125\n",
      "Epoch 195, Loss: 0.0037419127766042948, Accuracy: 99.91384887695312\n",
      "Epoch 196, Loss: 0.0035744765773415565, Accuracy: 99.92167663574219\n",
      "Epoch 197, Loss: 0.0036548550706356764, Accuracy: 99.91384887695312\n",
      "Epoch 198, Loss: 0.0034449307713657618, Accuracy: 99.92167663574219\n",
      "Epoch 199, Loss: 0.003498764242976904, Accuracy: 99.92951202392578\n",
      "Epoch 200, Loss: 0.004237567074596882, Accuracy: 99.9099349975586\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100))\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Question :  ['여기 기프티콘 되죠 \\n']\n",
      "Prediction Answer:  ['여기 진동 벨 가지 고 가 주문 불가능합니다 \\n']\n",
      "Real Answer :  ['\\t 네 현금영수증 해드릴까 요 \\n']\n",
      "_\n",
      "Question :  ['네 에 테이크 아웃 도 가능한가요 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 로 오시 면 테이크 아웃 잔 에 담아 드려요 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 톨 사이즈 로 주세요 \\n']\n",
      "Prediction Answer:  ['총 8800원 입니다 \\n']\n",
      "Real Answer :  ['\\t 따뜻한 거 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['진동 을 따로 주시나요 \\n']\n",
      "Prediction Answer:  ['네 잠시 드릴게요 \\n']\n",
      "Real Answer :  ['\\t 주 번호 로 드리겠습니다 \\n']\n",
      "_\n",
      "Question :  ['자리 있나요 \\n']\n",
      "Prediction Answer:  ['네 있습니다 \\n']\n",
      "Real Answer :  ['\\t 네 있습니다 \\n']\n",
      "_\n",
      "Question :  ['그럼 루이보스 밀크 티 하나 \\n']\n",
      "Prediction Answer:  ['네 포인트 는 사이즈 는 판매 하고 있습니다 \\n']\n",
      "Real Answer :  ['\\t 네 알겠습니다 \\n']\n",
      "_\n",
      "Question :  ['다음 에 무료 로 하고 엔 도장 찍어주세요 \\n']\n",
      "Prediction Answer:  ['네 쿠폰 받았습니다 \\n']\n",
      "Real Answer :  ['\\t 네 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 한 잔 에 얼마 죠 \\n']\n",
      "Prediction Answer:  ['4000원 입니다 \\n']\n",
      "Real Answer :  ['\\t 입니다 \\n']\n",
      "_\n",
      "Question :  ['얼마나 \\n']\n",
      "Prediction Answer:  ['스콘 은 개 아메리카노 샷 추가 텀블러 할인 해서 9500 입니다 \\n']\n",
      "Real Answer :  ['\\t 바로 만들어 드릴게요 \\n']\n",
      "_\n",
      "Question :  ['카푸치노 는 로 주시 고 아메리카노 는 로 \\n']\n",
      "Prediction Answer:  ['네 진동 벨 로 알려 드릴게요 \\n']\n",
      "Real Answer :  ['\\t 네 더 없으세요 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 는 어떤 종류 가 있나요 \\n']\n",
      "Prediction Answer:  ['네 초코 는 이랑 티 종류 있습니다 \\n']\n",
      "Real Answer :  ['\\t 디카 페인 과 기본 아메리카노 2 종류 있습니다 \\n']\n",
      "_\n",
      "Question :  ['카카오 페이 로 결제 가능한가요 \\n']\n",
      "Prediction Answer:  ['네 이에요 \\n']\n",
      "Real Answer :  ['\\t 네 가능합니다 \\n']\n",
      "_\n",
      "Question :  ['오늘 의 커피 는 커피 로 하나요 맛 이 \\n']\n",
      "Prediction Answer:  ['네 그건 시즌 한정 메뉴 라 로 가능하세요 \\n']\n",
      "Real Answer :  ['\\t 아 네 오늘 은 과테말라 커피 입니다 \\n']\n",
      "_\n",
      "Question :  ['머핀 은 뭐 가 제일 \\n']\n",
      "Prediction Answer:  ['베이글 은 초코 가 어떤 걸 로 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 블루베리 머핀 이 잘 나갑니다 \\n']\n",
      "_\n",
      "Question :  ['현금 영수증 해주세요 \\n']\n",
      "Prediction Answer:  ['네 번호 찍어주세요 \\n']\n",
      "Real Answer :  ['\\t 네 번호 찍어주세요 \\n']\n",
      "_\n",
      "Question :  ['둘 다 톨 사이즈 로 주세요 \\n']\n",
      "Prediction Answer:  ['총 8800원 입니다 \\n']\n",
      "Real Answer :  ['\\t 여기 서 드시고 요 \\n']\n",
      "_\n",
      "Question :  ['아이스 아메리카노 한 잔 가능한가요 \\n']\n",
      "Prediction Answer:  ['네 당연히 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 네 가능합니다 \\n']\n",
      "_\n",
      "Question :  ['아이스 아메리카노 에 샷 이 몇 개 \\n']\n",
      "Prediction Answer:  ['네 저희 아메리카노 치즈케이크 는 주문 주문 잔 치즈케이크 와 가요 \\n']\n",
      "Real Answer :  ['\\t 아이스 아메리카노 에 샷 은 개 \\n']\n",
      "_\n",
      "Question :  ['카페라테 한 잔 주세요 \\n']\n",
      "Prediction Answer:  ['네 카페라떼 컵 사이즈 는 뭘 로 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 카페라테 따뜻한 걸 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['아니요 \\n']\n",
      "Prediction Answer:  ['쓴맛 은 많이 없고 산미 나왔습니다 \\n']\n",
      "Real Answer :  ['\\t 네 더 필요하신 건 없으신 가요 \\n']\n",
      "_\n",
      "Question :  ['네 찍어주세요 \\n']\n",
      "Prediction Answer:  ['10 개 다모아 오시 면 커피한잔 드려요 \\n']\n",
      "Real Answer :  ['\\t 네 주문 딸기 스무디 와 쿠키 드릴게요 \\n']\n",
      "_\n",
      "Question :  ['시즌 메뉴 오늘 도 가능한가요 \\n']\n",
      "Prediction Answer:  ['네 여기 있습니다 \\n']\n",
      "Real Answer :  ['\\t 네 시즌 메뉴 가능합니다 \\n']\n",
      "_\n",
      "Question :  ['시즌 메뉴 와 함께 되어 있는 세트 메뉴 가 있나요 \\n']\n",
      "Prediction Answer:  ['네 캐리어 에 담아 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 치즈 케이크 와 시즌 메뉴 두 잔 으로 세트 메뉴 있습니다 \\n']\n",
      "_\n",
      "Question :  ['라테 에 우유 두 도 변경 가능한가요 \\n']\n",
      "Prediction Answer:  ['네 고객 님 살짝 케이크 500원 있습니다 \\n']\n",
      "Real Answer :  ['\\t 네 라테 에 두유 로 변경 가능합니다 \\n']\n",
      "_\n",
      "Question :  ['네 먹고 갈 거 예요 \\n']\n",
      "Prediction Answer:  ['가실 때 말씀 해주시면 테이크 아웃 잔 에 드릴 테 니 우선 머그잔 에 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 카드 여기 주세요 \\n']\n",
      "_\n",
      "Question :  ['카페인 이 음료 있나요 \\n']\n",
      "Prediction Answer:  ['아니요 있습니다 \\n']\n",
      "Real Answer :  ['\\t 티 음료 와 스무디 에는 카페인 이 않습니다 \\n']\n",
      "_\n",
      "Question :  ['딸기스무디 랑 키위 스무디 는 생 과일 인가요 \\n']\n",
      "Prediction Answer:  ['아메리카노 한 아메리카노 라테 아메리카노 다 아이스 아메리카노 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 딸기 는 키위 는 생 과일 을 사용 하고 있습니다 \\n']\n",
      "_\n",
      "Question :  ['그럼 딸기 스무디 하나 주세요 \\n']\n",
      "Prediction Answer:  ['네 사이즈 는 어떤 걸 로 주문 넣어 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 드시고 가시나요 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 한 잔이요 \\n']\n",
      "Prediction Answer:  ['아이스 아메리카노 포장 이신 가요 \\n']\n",
      "Real Answer :  ['\\t 아이스 아메리카노 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['네 도 같이 \\n']\n",
      "Prediction Answer:  ['네 이리 주세요 \\n']\n",
      "Real Answer :  ['\\t 네 아메리카노 4000원 입니다 \\n']\n",
      "_\n",
      "Question :  ['디카 페인 아이스 아메리카노 한 잔 주세요 \\n']\n",
      "Prediction Answer:  ['네 사이즈 는 어떤 걸 로 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 디카 페인 아이스 아메리카노 는 기존 금액 에 300원 추가 되는데 괜찮으신 가요 \\n']\n",
      "_\n",
      "Question :  ['커피 음료 것 뭐 가 있나요 \\n']\n",
      "Prediction Answer:  ['네 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 스무디 와 주스 있습니다 \\n']\n",
      "_\n",
      "Question :  ['주스 어떤 종류 있나요 \\n']\n",
      "Prediction Answer:  ['어니언 서 안내 직접 있어요 \\n']\n",
      "Real Answer :  ['\\t 딸기 주스 주스 주스 가 있습니다 \\n']\n",
      "_\n",
      "Question :  ['플랫 화이트 라지 로 주세요 \\n']\n",
      "Prediction Answer:  ['저희 맛 과 고소한 맛 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 네 \\n']\n",
      "_\n",
      "Question :  ['네 레드 벨벳 케이크 주세요 \\n']\n",
      "Prediction Answer:  ['카페모카 사이즈 는 어떤 걸 로 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 음료 는 뭘 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['네 먹고 갈 거 예요 \\n']\n",
      "Prediction Answer:  ['가실 때 말씀 해주시면 테이크 아웃 잔 에 드릴 테 니 우선 머그잔 에 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 유리잔 괜찮으세요 \\n']\n",
      "_\n",
      "Question :  ['따뜻한 밀크 티 주세요 \\n']\n",
      "Prediction Answer:  ['카페모카 하시는 도 와 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 \\n']\n",
      "_\n",
      "Question :  ['음료 얼마나 하나요 \\n']\n",
      "Prediction Answer:  ['아메리카노 은 아메리카노 만 한 있습니다 \\n']\n",
      "Real Answer :  ['\\t 10분 정도 주시 면 됩니다 \\n']\n",
      "_\n",
      "Question :  ['아이스 아메리카노 한잔 얼마 인가요 \\n']\n",
      "Prediction Answer:  ['아이스 아메리카노 1 잔 은 아이스 잔 은 아이스 아메리카노 은 잔 아메리카노 아메리카노 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 4500원 입니다 \\n']\n",
      "_\n",
      "Question :  ['현금영수증 번호 \\n']\n",
      "Prediction Answer:  ['네 진동 벨 울리면 찾으러 오세요 \\n']\n",
      "Real Answer :  ['\\t 네 \\n']\n",
      "_\n",
      "Question :  ['이 카드 로 결제 해주세요 \\n']\n",
      "Prediction Answer:  ['네 결제 해드렸습니다 \\n']\n",
      "Real Answer :  ['\\t 네 결제 도 와 드릴게요 \\n']\n",
      "_\n",
      "Question :  ['주문 한 게 다 안 \\n']\n",
      "Prediction Answer:  ['베이글 은 아메리카노 가 입니다 \\n']\n",
      "Real Answer :  ['\\t 주 번호 가 몇 이 죠 \\n']\n",
      "_\n",
      "Question :  ['을 \\n']\n",
      "Prediction Answer:  ['머그잔 으로 제공 해드려도 괜찮을까요 \\n']\n",
      "Real Answer :  ['\\t \\n']\n",
      "_\n",
      "Question :  ['베이글 은 얼마 인가요 \\n']\n",
      "Prediction Answer:  ['베이글 과 동일하게 2000원 입니다 \\n']\n",
      "Real Answer :  ['\\t 베이글 은 2000원 입니다 \\n']\n",
      "_\n",
      "Question :  ['지금 되나요 \\n']\n",
      "Prediction Answer:  ['네 멤버십 죠 \\n']\n",
      "Real Answer :  ['\\t 는 계절 메뉴 라 지금 은 판매 하지 않습니다 \\n']\n",
      "_\n",
      "Question :  ['바닐라 라테 는 따뜻하게 주세요 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 적립 이나 할인 카드 있으세요 \\n']\n",
      "_\n",
      "Question :  ['테이크 아웃 으로 부탁드립니다 \\n']\n",
      "Prediction Answer:  ['네 진동 캐리어 많이 로 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 결제 는 이 쪽 에서 도 와 드릴게요 \\n']\n",
      "_\n",
      "Question :  ['혹시 테이크 아웃 잔 에 수 있나요 \\n']\n",
      "Prediction Answer:  ['네 고객 님 포인트 페인 지금 하시겠어요 \\n']\n",
      "Real Answer :  ['\\t 테이크 아웃 하시는 건가 요 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 하나 는 샷 추가 해주세요 \\n']\n",
      "Prediction Answer:  ['네 아이스 아메리카노 두 주문 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 아메리카노 는 둘 다 따뜻한 걸 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['쿠폰 찍어주세요 \\n']\n",
      "Prediction Answer:  ['10 개 다모아 오시 면 커피한잔 드려요 \\n']\n",
      "Real Answer :  ['\\t 네 찍어 드릴게요 \\n']\n",
      "_\n",
      "Question :  ['주문 할게요 \\n']\n",
      "Prediction Answer:  ['네 어떤 걸 로 하시겠습니까 \\n']\n",
      "Real Answer :  ['\\t 어떤 거 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['파나요 \\n']\n",
      "Prediction Answer:  ['네 자리 에 자리 많아요 \\n']\n",
      "Real Answer :  ['\\t 는 계절 지금 은 \\n']\n",
      "_\n",
      "Question :  ['그럼 겨울 메뉴 뭐 가 \\n']\n",
      "Prediction Answer:  ['초코 머핀 데워 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 겨울 엔 감귤 라테 가 제일 많이 나가요 \\n']\n",
      "_\n",
      "Question :  ['네 결제 는 카드 로 할게요 \\n']\n",
      "Prediction Answer:  ['네 계산 해드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 결제 완료 되었습니다 \\n']\n",
      "_\n",
      "Question :  ['둘 다 사이즈 로 할게요 \\n']\n",
      "Prediction Answer:  ['총 50 개 팔렸어요 \\n']\n",
      "Real Answer :  ['\\t 네 결제 는 어떤 것 으로 도 와 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['기프티콘 으로 결제 할게요 \\n']\n",
      "Prediction Answer:  ['저 한테 보여주시고 제 가 확인 버튼 누르면 돼요 \\n']\n",
      "Real Answer :  ['\\t 네 그럼 쿠폰 저 \\n']\n",
      "_\n",
      "Question :  ['녹차 라테 1 잔 주세요 \\n']\n",
      "Prediction Answer:  ['드시고 가시나요 \\n']\n",
      "Real Answer :  ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['네 그럼 휘핑크림 추가 해서 주세요 \\n']\n",
      "Prediction Answer:  ['저희 투 샷 샷 들어가는데 추가 해드릴까 요 \\n']\n",
      "Real Answer :  ['\\t 네 녹차 라테 에 휘핑크림 추가 해서 4500원 입니다 \\n']\n",
      "_\n",
      "Question :  ['브레드 종류 는 뭐 가 있나요 \\n']\n",
      "Prediction Answer:  ['요즘 초코 이랑 플레인 티 있습니다 \\n']\n",
      "Real Answer :  ['\\t 허니 브레드 와 갈릭 치즈 브레드 가 있습니다 \\n']\n",
      "_\n",
      "Question :  ['생크림 이 건 어떤 건가 요 \\n']\n",
      "Prediction Answer:  ['네 진동 벨 로 없으세요 \\n']\n",
      "Real Answer :  ['\\t 허니 브레드 입니다 \\n']\n",
      "_\n",
      "Question :  ['네 그렇게 만들어 주세요 \\n']\n",
      "Prediction Answer:  ['네 진동 벨 이 울리면 픽업 대로 와주세요 \\n']\n",
      "Real Answer :  ['\\t 더 필요한 건 없으세요 \\n']\n",
      "_\n",
      "Question :  ['여기 있습니다 \\n']\n",
      "Prediction Answer:  ['손님 지금 15000 포인트 있으신 데 사용 해 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 네 확인 되셨고 되면 진동 벨 거 예요 \\n']\n",
      "_\n",
      "Question :  ['핫초코 한 잔 아메리카노 사이 즈 업 한 잔 하면 얼마 인가요 \\n']\n",
      "Prediction Answer:  ['9500원 입니다 \\n']\n",
      "Real Answer :  ['\\t 입니다 \\n']\n",
      "_\n",
      "Question :  ['주스 는 다른 건 없나요 \\n']\n",
      "Prediction Answer:  ['네 고객 님 포인트 케이크 다 다 있습니다 \\n']\n",
      "Real Answer :  ['\\t 그럼 에 라테 추천 \\n']\n",
      "_\n",
      "Question :  ['그건 \\n']\n",
      "Prediction Answer:  ['자리 에 앉아 계시 면 가져다 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 만 따듯 해 요 \\n']\n",
      "_\n",
      "Question :  ['통신사 할인 되죠 \\n']\n",
      "Prediction Answer:  ['대략 5분 정도 걸립니다 \\n']\n",
      "Real Answer :  ['\\t 네 300원 할인 됩니다 \\n']\n",
      "_\n",
      "Question :  ['매장 에서 언제 까지 영업 하시나요 \\n']\n",
      "Prediction Answer:  ['네 있습니다 \\n']\n",
      "Real Answer :  ['\\t 오후 10시 까지 영업 입니다 \\n']\n",
      "_\n",
      "Question :  ['아니요 그냥 주세요 \\n']\n",
      "Prediction Answer:  ['카페모카 5천 원 입니다 \\n']\n",
      "Real Answer :  ['\\t 결제 해드릴게요 \\n']\n",
      "_\n",
      "Question :  ['가격 안 되나요 \\n']\n",
      "Prediction Answer:  ['네 자몽 만 가능하세요 \\n']\n",
      "Real Answer :  ['\\t 한 해드릴게요 \\n']\n",
      "_\n",
      "Question :  ['카페라테 한잔 주세요 \\n']\n",
      "Prediction Answer:  ['네 카페라떼 컵 사이즈 는 뭘 로 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['네 차가운 걸 로 주세요 \\n']\n",
      "Prediction Answer:  ['드시고 가시나요 \\n']\n",
      "Real Answer :  ['\\t 4500원 입니다 \\n']\n",
      "_\n",
      "Question :  ['어떤 게 괜찮아요 \\n']\n",
      "Prediction Answer:  ['아니요 있습니다 \\n']\n",
      "Real Answer :  ['\\t 이나 원두 를 하시는 게 아니면 예 가체 많이 추천 \\n']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "Question :  ['그럼 추천 치즈 케이크 도 같이 주세요 \\n']\n",
      "Prediction Answer:  ['네 다 나 같이 같이 해드릴게요 \\n']\n",
      "Real Answer :  ['\\t 네 매장 에서 드시고 가시나요 \\n']\n",
      "_\n",
      "Question :  ['그리고 휘핑크림 은 에스프레소 크림 으로 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 결제 는 어떻게 해드릴까 요 \\n']\n",
      "_\n",
      "Question :  ['지금 도 할인 하나요 \\n']\n",
      "Prediction Answer:  ['네 2 찍어 드렸고 진동 벨 로 알려 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 10시 까지 하고 있습니다 \\n']\n",
      "_\n",
      "Question :  ['그럼 와 아이스 아메리카노 로 할게요 \\n']\n",
      "Prediction Answer:  ['네 아이스 머핀 두 잔 치즈 케이크 주문 받았습니다 \\n']\n",
      "Real Answer :  ['\\t 더 필요하신 건 없나요 \\n']\n",
      "_\n",
      "Question :  ['네 할인 적립 은 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 바코드 \\n']\n",
      "_\n",
      "Question :  ['초코 프라푸치노 주세요 \\n']\n",
      "Prediction Answer:  ['네 아이스 프라푸치노 몇 잔 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 휘핑 올려 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['시럽 도 가 \\n']\n",
      "Prediction Answer:  ['유리잔 에 컵 아닌데요 \\n']\n",
      "Real Answer :  ['\\t 드시고 가시나요 \\n']\n",
      "_\n",
      "Question :  ['둘 다 사이즈 로 주세요 \\n']\n",
      "Prediction Answer:  ['총 8800원 입니다 \\n']\n",
      "Real Answer :  ['\\t 드시고 가시나요 \\n']\n",
      "_\n",
      "Question :  ['마시다가 갈 건데 테이크아웃 으로 주세요 \\n']\n",
      "Prediction Answer:  ['네 계산 해드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 상 매장 에서는 머그컵 으로 드리고 있어요 \\n']\n",
      "_\n",
      "Question :  ['나갈 때 테이크아웃 컵 으로 수 있나요 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 그렇게 해드릴게요 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 두 잔 한잔 주세요 \\n']\n",
      "Prediction Answer:  ['드시고 가시나요 \\n']\n",
      "Real Answer :  ['\\t 드시고 가실 건가 요 \\n']\n",
      "_\n",
      "Question :  ['얼마나 하나요 \\n']\n",
      "Prediction Answer:  ['쓴맛 은 많이 없고 산미 가 있고 다른 원두 들 보다 과일 향 이 나죠 \\n']\n",
      "Real Answer :  ['\\t 5분 정도 \\n']\n",
      "_\n",
      "Question :  ['포인트 적립 해주세요 \\n']\n",
      "Prediction Answer:  ['네 결제 도 같이 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 번호 입력 부탁드립니다 \\n']\n",
      "_\n",
      "Question :  ['네 번호 로 할게요 \\n']\n",
      "Prediction Answer:  ['주차 는 하셨나요 \\n']\n",
      "Real Answer :  ['\\t 네 에 번호 \\n']\n",
      "_\n",
      "Question :  ['아 포인트 포인트 사용 해주세요 \\n']\n",
      "Prediction Answer:  ['네 가능해요 \\n']\n",
      "Real Answer :  ['\\t 네 고객 님 포인트 총 있으신 데 사용 도 와 드리겠습니다 \\n']\n",
      "_\n",
      "Question :  ['톨 사이즈 로 주문 할게요 \\n']\n",
      "Prediction Answer:  ['총 50 개 주문 받았습니다 \\n']\n",
      "Real Answer :  ['\\t 네 계산 도 와 드리겠습니다 \\n']\n",
      "_\n",
      "Question :  ['아메리카노 사이즈 가능한가요 \\n']\n",
      "Prediction Answer:  ['네 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 네 500원 만 추가 하시면 가능하십니다 \\n']\n",
      "_\n",
      "Question :  ['사이 즈 업 해서 주세요 \\n']\n",
      "Prediction Answer:  ['네 아이스 벨 로 드릴 까요 \\n']\n",
      "Real Answer :  ['\\t 네 결제 는 어떻게 도 와 드릴 까요 \\n']\n",
      "_\n",
      "Question :  ['커피 는 텀블러 에 담아주세요 \\n']\n",
      "Prediction Answer:  ['텀블러 할인 300원 같이 해드릴게요 \\n']\n",
      "Real Answer :  ['\\t 네 텀블러 할인 4000원 결제 도 와 드리겠습니다 \\n']\n",
      "_\n",
      "Question :  ['아니요 아이스 로 주세요 \\n']\n",
      "Prediction Answer:  ['레귤러 사이즈 로 괜찮으세요 \\n']\n",
      "Real Answer :  ['\\t 드시고 가실 건가 요 \\n']\n",
      "_\n",
      "Question :  ['테이크아웃 할게요 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 지금 중 인데 케이크 주문 하시면 아메리카노 한잔 로 드려요 \\n']\n",
      "_\n",
      "Question :  ['현금 결제 가 안 \\n']\n",
      "Prediction Answer:  ['네 있습니다 \\n']\n",
      "Real Answer :  ['\\t 현금 은 에서 주문 도 와 드리겠습니다 \\n']\n",
      "_\n",
      "Question :  ['포인트 적립 되나요 \\n']\n",
      "Prediction Answer:  ['네 됩니다 \\n']\n",
      "Real Answer :  ['\\t 번호 포인트 적립 도 와 드리고 있어요 \\n']\n",
      "_\n",
      "Question :  ['포인트 적립 할게요 \\n']\n",
      "Prediction Answer:  ['네 결제 도 와 드리겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 결제 되셨습니다 \\n']\n",
      "_\n",
      "Question :  ['티라미수 는 있나요 \\n']\n",
      "Prediction Answer:  ['네 있습니다 \\n']\n",
      "Real Answer :  ['\\t 네 티라미수 는 있습니다 \\n']\n",
      "_\n",
      "Question :  ['네 현금영수증 해주세요 \\n']\n",
      "Prediction Answer:  ['네 번호 주세요 \\n']\n",
      "Real Answer :  ['\\t 네 드시고 가시나요 \\n']\n",
      "_\n",
      "Question :  ['샷 추가 해주세요 \\n']\n",
      "Prediction Answer:  ['네 알겠습니다 \\n']\n",
      "Real Answer :  ['\\t 네 알겠습니다 \\n']\n",
      "_\n",
      "Question :  ['얼마 에요 \\n']\n",
      "Prediction Answer:  ['플랫 화이트 4500원 입니다 \\n']\n",
      "Real Answer :  ['\\t 만 원 입니다 \\n']\n",
      "_\n",
      "Question :  ['아이스 아메리카노 랑 샌드위치 주세요 \\n']\n",
      "Prediction Answer:  ['카페모카 5천 하면 가능합니다 \\n']\n",
      "Real Answer :  ['\\t 10시 에 세트 할인 가능하세요 \\n']\n"
     ]
    }
   ],
   "source": [
    "for test_seq, test_labels in test_ds:\n",
    "    prediction = test_step(model, test_seq)\n",
    "    test_text = tokenizer.sequences_to_texts(test_seq.numpy())\n",
    "    gt_text = tokenizer.sequences_to_texts(test_labels.numpy())\n",
    "    texts = tokenizer.sequences_to_texts(prediction.numpy())\n",
    "    print('_')\n",
    "    print('Question : ', test_text)\n",
    "    print('Prediction Answer: ', texts)\n",
    "    print('Real Answer : ', gt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
