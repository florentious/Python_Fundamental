{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter\n",
    "\n",
    "EPOCHS = 50\n",
    "NUM_WORDS = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = 'c:/dev/dataset/wikihowAll_pre.csv'\n",
    "\n",
    "origin_data = pd.read_csv(origin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Keep related supplies in the same area.Make an...</td>\n",
       "      <td>How to Be an Organized Artist1</td>\n",
       "      <td>If you're a photographer keep all the necessa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Create a sketch in the NeoPopRealist manner of...</td>\n",
       "      <td>How to Create a Neopoprealist Art Work</td>\n",
       "      <td>See the image for how this drawing develops s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Get a bachelor’s degree.Enroll in a studio-bas...</td>\n",
       "      <td>How to Be a Visual Effects Artist1</td>\n",
       "      <td>It is possible to become a VFX artist without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Start with some experience or interest in art....</td>\n",
       "      <td>How to Become an Art Investor</td>\n",
       "      <td>The best art investors do their research on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Keep your reference materials sketches article...</td>\n",
       "      <td>How to Be an Organized Artist2</td>\n",
       "      <td>As you start planning for a project or work y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214289</td>\n",
       "      <td>Consider changing the spelling of your name.Av...</td>\n",
       "      <td>How to Pick a Stage Name3</td>\n",
       "      <td>If you have a name that you like you might fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214290</td>\n",
       "      <td>Try out your name.Don’t legally change your na...</td>\n",
       "      <td>How to Pick a Stage Name4</td>\n",
       "      <td>Your name might sound great to you when you s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214291</td>\n",
       "      <td>Understand the process of relief printing.Exam...</td>\n",
       "      <td>How to Identify Prints1</td>\n",
       "      <td>Relief printing is the oldest and most tradit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214292</td>\n",
       "      <td>Understand the process of intaglio printing.Lo...</td>\n",
       "      <td>How to Identify Prints2</td>\n",
       "      <td>Intaglio is Italian for \"incis­ing\" and corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214293</td>\n",
       "      <td>Understand the different varieties of lithogra...</td>\n",
       "      <td>How to Identify Prints3</td>\n",
       "      <td>Lithography is a big term often used to refer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "0       Keep related supplies in the same area.Make an...   \n",
       "1       Create a sketch in the NeoPopRealist manner of...   \n",
       "2       Get a bachelor’s degree.Enroll in a studio-bas...   \n",
       "3       Start with some experience or interest in art....   \n",
       "4       Keep your reference materials sketches article...   \n",
       "...                                                   ...   \n",
       "214289  Consider changing the spelling of your name.Av...   \n",
       "214290  Try out your name.Don’t legally change your na...   \n",
       "214291  Understand the process of relief printing.Exam...   \n",
       "214292  Understand the process of intaglio printing.Lo...   \n",
       "214293  Understand the different varieties of lithogra...   \n",
       "\n",
       "                                         title  \\\n",
       "0               How to Be an Organized Artist1   \n",
       "1       How to Create a Neopoprealist Art Work   \n",
       "2           How to Be a Visual Effects Artist1   \n",
       "3                How to Become an Art Investor   \n",
       "4               How to Be an Organized Artist2   \n",
       "...                                        ...   \n",
       "214289               How to Pick a Stage Name3   \n",
       "214290               How to Pick a Stage Name4   \n",
       "214291                 How to Identify Prints1   \n",
       "214292                 How to Identify Prints2   \n",
       "214293                 How to Identify Prints3   \n",
       "\n",
       "                                                     text  \n",
       "0        If you're a photographer keep all the necessa...  \n",
       "1        See the image for how this drawing develops s...  \n",
       "2        It is possible to become a VFX artist without...  \n",
       "3        The best art investors do their research on t...  \n",
       "4        As you start planning for a project or work y...  \n",
       "...                                                   ...  \n",
       "214289   If you have a name that you like you might fi...  \n",
       "214290   Your name might sound great to you when you s...  \n",
       "214291   Relief printing is the oldest and most tradit...  \n",
       "214292   Intaglio is Italian for \"incis­ing\" and corre...  \n",
       "214293   Lithography is a big term often used to refer...  \n",
       "\n",
       "[214294 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_data = origin_data.drop(origin_data.columns[0], axis=1)\n",
    "origin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data = origin_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = origin_data['text'], origin_data.headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized dictionary\n",
    "def tokenized_to_dic(df) :\n",
    "    x_token = defaultdict(int)\n",
    "    y_token = defaultdict(int)\n",
    "\n",
    "    for idx in range(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder & decoder\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # 입력이 one-hot-encdoing 형식으로 들어오면 embedding을 수행을 먼저\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n",
    "        # 그리고 LSTM에서 hidden state을 출력으로 던져주어야 이것을 활용해서 return을 활용할 수 있다...\n",
    "        # return_sequence=True : 디코더에서 나오는 것 하나하나 알아야 하기에...\n",
    "        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n",
    "        # return_sequences = True -> attention 하기 위해서\n",
    "\n",
    "    # 인코더의 경우에는 입력이 들어오면 이것을 바탕으로 히든, 셀 스테이트를 하도록 ...\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.emb(x)\n",
    "        # h,c는 test를 할 경우에는 다음으로 넘겨 주어야 forward  로 계산을 하면서 나갈 수 있으니..\n",
    "        H, h, c = self.lstm(x)\n",
    "        return H, h, c\n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n",
    "        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n",
    "        \n",
    "        #****Attention을 추가함!!!! \n",
    "        self.att = tf.keras.layers.Attention()\n",
    "        \n",
    "        # 최종 단어 단에서 어떤 것을 할 것인지..선택..\n",
    "        self.dense = tf.keras.layers.Dense(NUM_WORDS, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        # ***처음 들어오는 인코더 단에서 넘어오는 것들을 받고,,\n",
    "        x, s0, c0, H = inputs\n",
    "        x = self.emb(x)\n",
    "        # ****S는 hidden state를 모두 모아둔 부분..--> 쿼리로 사용을 할 것임....--->하나 앞선 시간을 사용을 해서..\n",
    "        S, h, c = self.lstm(x, initial_state=[s0, c0])\n",
    "        # ***쿼리로 사용을 할 것임....--->하나 앞선 시간을 사용을 해서..(1차원을 3차원으로 확장) & 마지막 히든은 제외...해서 :-1까지..\n",
    "        S_ = tf.concat([s0[:, tf.newaxis, :], S[:, :-1, :]], axis=1)\n",
    "        # ****키와 value를 계산하고,,,\n",
    "        A = self.att([S_, H])\n",
    "        y = tf.concat([S, A], axis=-1)\n",
    "        \n",
    "        return self.dense(y), h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq\n",
    "class Seq2seq(tf.keras.Model):\n",
    "    def __init__(self, sos, eos):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        # 1) 가장 기본적으로 필요한 Encoder, Deoder, sos, eos에 관련된 부분을 지정을 함!!!!\n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "        self.sos = sos\n",
    "        self.eos = eos\n",
    "    \n",
    "    # 연결에서 구성 --> 학습을 위해서는 입력/출력 모두 알아야 하기에 x,y = input으로 받음\n",
    "    # 그리고 디코더에 입력을 넣어주어야 하기에..\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "       # (학습 과정)\n",
    "        if training is True:\n",
    "            # 학습을 위해서는 입력/출력 모두 알아야 하기에 x,y = input으로 받음\n",
    "            # 그리고 디코더에 입력을 넣어주어야 하기에..\n",
    "            x, y = inputs\n",
    "            # encoder에 입력  x를 넣어서 나온 hidden state, cell  (LSTM으로 구현이 되어서..)\n",
    "            H, h, c = self.enc(x)\n",
    "            # 최종 출력 y를 하도록...\n",
    "            y, _, _ = self.dec((y, h, c, H))\n",
    "            return y\n",
    "        # (Test 과정) --> 그러니 정답  y는 없음..\n",
    "        else:\n",
    "            x = inputs\n",
    "            H, h, c = self.enc(x)\n",
    "            # 뒤에 디커더 부분에 입력을 넣어 주는 부분이 달라지게 된다!!!! --> sos  를 넣어준다.\n",
    "            y = tf.convert_to_tensor(self.sos)\n",
    "            y = tf.reshape(y, (1, 1))\n",
    "\n",
    "            # 최대 seq는 64길이까지만..\n",
    "            seq = tf.TensorArray(tf.int32, 64)\n",
    "            \n",
    "            # tf의  for loop으로 사용을 해서 최대 64까지 \n",
    "            for idx in tf.range(64):\n",
    "                # for 에서 처음에는 처음으로 만들어준 sos를 decoder에 입력으로 넣어주고 --> self.dec(y,h,c,H)을 해서\n",
    "                # 출력인 y와 hidden state, cell state를 출력으로 준다.\n",
    "                y, h, c = self.dec([y, h, c, H])\n",
    "                # 가장 큰 y값에 대한 index를 얻어오게 되는 과정\n",
    "                y = tf.cast(tf.argmax(y, axis=-1), dtype=tf.int32)\n",
    "                # reshape를 하면서 batch를 사용을 하기 위해서...\n",
    "                y = tf.reshape(y, (1, 1))\n",
    "                # seq를 하나씩 받으면서 처리하기 위해서...\n",
    "                seq = seq.write(idx, y)\n",
    "                # eos일 때 까지 for lopp순환\n",
    "                if y == self.eos:\n",
    "                    break\n",
    "            # \n",
    "            return tf.reshape(seq.stack(), (1, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement training loop\n",
    "@tf.function\n",
    "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    # 마지맞 eos는 있고, 처음 sos 는 없는 것...\n",
    "    output_labels = labels[:, 1:]\n",
    "    # 처음 sos는 포함이 되고, 마지막 eos는 빼고...\n",
    "    shifted_labels = labels[:, :-1]\n",
    "    # 그래서 위의 시프트 된 것들이 아래의 model의 학습 과정에 들어가게 된다!!!!!\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 위의 output_labels, shifted_labels 이 들어가게 된다...\n",
    "        predictions = model([inputs, shifted_labels], training=True)\n",
    "        loss = loss_object(output_labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(output_labels, predictions)\n",
    "\n",
    "# Implement algorithm test\n",
    "@tf.function\n",
    "def test_step(model, inputs):\n",
    "    return model(inputs, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = list(x[:5000].apply(lambda x : x+'\\n'))\n",
    "y_sub = list(y[:5000].apply(lambda x : '\\t'+x+'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = len(x_sub)\n",
    "\n",
    "# 질문을 보고 한 번 데이터 셋을 섞어준다..\n",
    "perm = list(range(num_sample))\n",
    "random.seed(0)\n",
    "random.shuffle(perm)\n",
    "# 섞으면서 train/ test로 구분을 하기 위한 것..\n",
    "train_q = list()\n",
    "train_a = list()\n",
    "test_q = list()\n",
    "test_a = list()\n",
    "\n",
    "# 질문과 답변에 대한 것을 돌면서...\n",
    "for idx, qna in enumerate(zip(x_sub, y_sub)):\n",
    "    q, a = qna\n",
    "    # 5/1은 test, 5/4는 train\n",
    "    if perm[idx] > num_sample//5:\n",
    "        train_q.append(q)\n",
    "        train_a.append(a)\n",
    "    else:\n",
    "        test_q.append(q)\n",
    "        test_a.append(a)\n",
    "\n",
    "# 문장에서 짤라주는 것에 대한 세팅...\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS,\n",
    "                                                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "tokenizer.fit_on_texts(train_q + train_a)\n",
    "\n",
    "train_q_seq = tokenizer.texts_to_sequences(train_q)\n",
    "train_a_seq = tokenizer.texts_to_sequences(train_a)\n",
    "\n",
    "test_q_seq = tokenizer.texts_to_sequences(test_q)\n",
    "test_a_seq = tokenizer.texts_to_sequences(test_a)\n",
    "\n",
    "# 입력은 뒤로...패딩..\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(train_q_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=64)\n",
    "# 출력은 앞에로 패딩..\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(train_a_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=65)\n",
    "\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(test_q_seq,\n",
    "                                                       value=0,\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=64)\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(test_a_seq,\n",
    "                                                       value=0,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=65)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(1).prefetch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Seq2seq(sos=tokenizer.word_index['\\t'],\n",
    "                eos=tokenizer.word_index['\\n'])\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define performance metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.351285934448242, Accuracy: 42.09489822387695\n",
      "Epoch 2, Loss: 3.7813518047332764, Accuracy: 44.473228454589844\n",
      "Epoch 3, Loss: 3.649198532104492, Accuracy: 45.32344055175781\n",
      "Epoch 4, Loss: 3.485776424407959, Accuracy: 46.4370002746582\n",
      "Epoch 5, Loss: 3.342334270477295, Accuracy: 47.613075256347656\n",
      "Epoch 6, Loss: 3.2132675647735596, Accuracy: 48.48126220703125\n",
      "Epoch 7, Loss: 3.0872557163238525, Accuracy: 49.288883209228516\n",
      "Epoch 8, Loss: 2.976085662841797, Accuracy: 50.017189025878906\n",
      "Epoch 9, Loss: 2.8648040294647217, Accuracy: 50.814266204833984\n",
      "Epoch 10, Loss: 2.75075101852417, Accuracy: 51.64415740966797\n",
      "Epoch 11, Loss: 2.6351394653320312, Accuracy: 52.297447204589844\n",
      "Epoch 12, Loss: 2.524951219558716, Accuracy: 53.15352249145508\n",
      "Epoch 13, Loss: 2.4113383293151855, Accuracy: 54.142051696777344\n",
      "Epoch 14, Loss: 2.3014323711395264, Accuracy: 55.19661331176758\n",
      "Epoch 15, Loss: 2.189403772354126, Accuracy: 56.438720703125\n",
      "Epoch 16, Loss: 2.0746588706970215, Accuracy: 57.9058837890625\n",
      "Epoch 17, Loss: 1.9660718441009521, Accuracy: 59.43829345703125\n",
      "Epoch 18, Loss: 1.857222557067871, Accuracy: 61.179359436035156\n",
      "Epoch 19, Loss: 1.749525785446167, Accuracy: 62.956756591796875\n",
      "Epoch 20, Loss: 1.6481366157531738, Accuracy: 64.77009582519531\n",
      "Epoch 21, Loss: 1.5521239042282104, Accuracy: 66.52053833007812\n",
      "Epoch 22, Loss: 1.454892873764038, Accuracy: 68.27644348144531\n",
      "Epoch 23, Loss: 1.3676786422729492, Accuracy: 69.94873809814453\n",
      "Epoch 24, Loss: 1.2769900560379028, Accuracy: 71.86054229736328\n",
      "Epoch 25, Loss: 1.1939104795455933, Accuracy: 73.53947448730469\n",
      "Epoch 26, Loss: 1.1129283905029297, Accuracy: 75.34930419921875\n",
      "Epoch 27, Loss: 1.0401874780654907, Accuracy: 76.89891815185547\n",
      "Epoch 28, Loss: 0.9666668176651001, Accuracy: 78.53799438476562\n",
      "Epoch 29, Loss: 0.8989637494087219, Accuracy: 80.12940979003906\n",
      "Epoch 30, Loss: 0.8357870578765869, Accuracy: 81.63603210449219\n",
      "Epoch 31, Loss: 0.7754052877426147, Accuracy: 83.08131408691406\n",
      "Epoch 32, Loss: 0.7163921594619751, Accuracy: 84.50745391845703\n",
      "Epoch 33, Loss: 0.6595816016197205, Accuracy: 85.86170196533203\n",
      "Epoch 34, Loss: 0.6066799163818359, Accuracy: 87.1905517578125\n",
      "Epoch 35, Loss: 0.5573628544807434, Accuracy: 88.54167175292969\n",
      "Epoch 36, Loss: 0.5104050040245056, Accuracy: 89.62865447998047\n",
      "Epoch 37, Loss: 0.46661078929901123, Accuracy: 90.83052062988281\n",
      "Epoch 38, Loss: 0.42446279525756836, Accuracy: 91.85811614990234\n",
      "Epoch 39, Loss: 0.3841651380062103, Accuracy: 92.98066711425781\n",
      "Epoch 40, Loss: 0.35054826736450195, Accuracy: 93.83869171142578\n",
      "Epoch 41, Loss: 0.3173949122428894, Accuracy: 94.70452880859375\n",
      "Epoch 42, Loss: 0.29097050428390503, Accuracy: 95.26795959472656\n",
      "Epoch 43, Loss: 0.2601221799850464, Accuracy: 96.12286376953125\n",
      "Epoch 44, Loss: 0.23490595817565918, Accuracy: 96.6761245727539\n",
      "Epoch 45, Loss: 0.20934462547302246, Accuracy: 97.30284118652344\n",
      "Epoch 46, Loss: 0.18317998945713043, Accuracy: 97.90455627441406\n",
      "Epoch 47, Loss: 0.16169625520706177, Accuracy: 98.38397216796875\n",
      "Epoch 48, Loss: 0.1468830704689026, Accuracy: 98.63130187988281\n",
      "Epoch 49, Loss: 0.13345670700073242, Accuracy: 98.8536148071289\n",
      "Epoch 50, Loss: 0.12151511013507843, Accuracy: 99.05874633789062\n",
      "Epoch 51, Loss: 0.11304010450839996, Accuracy: 99.16775512695312\n",
      "Epoch 52, Loss: 0.10250557214021683, Accuracy: 99.29240417480469\n",
      "Epoch 53, Loss: 0.09092909097671509, Accuracy: 99.47135162353516\n",
      "Epoch 54, Loss: 0.08150430023670197, Accuracy: 99.55770111083984\n",
      "Epoch 55, Loss: 0.0725763589143753, Accuracy: 99.65421295166016\n",
      "Epoch 56, Loss: 0.06903225928544998, Accuracy: 99.66944885253906\n",
      "Epoch 57, Loss: 0.06300293654203415, Accuracy: 99.72688293457031\n",
      "Epoch 58, Loss: 0.056757234036922455, Accuracy: 99.7726058959961\n",
      "Epoch 59, Loss: 0.053049392998218536, Accuracy: 99.80229187011719\n",
      "Epoch 60, Loss: 0.05527720972895622, Accuracy: 99.72962188720703\n",
      "Epoch 61, Loss: 0.08520104736089706, Accuracy: 99.04547119140625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-bfc4910999f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mseqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Epoch {}, Loss: {}, Accuracy: {}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100))\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "for test_seq, test_labels in test_ds:\n",
    "    prediction = test_step(model, test_seq)\n",
    "    test_text = tokenizer.sequences_to_texts(test_seq.numpy())\n",
    "    gt_text = tokenizer.sequences_to_texts(test_labels.numpy())\n",
    "    texts = tokenizer.sequences_to_texts(prediction.numpy())\n",
    "    print('_')\n",
    "    print('Question : ', test_text)\n",
    "    print('Prediction Answer: ', texts)\n",
    "    print('Real Answer : ', gt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
